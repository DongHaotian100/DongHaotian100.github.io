<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>MapReduce Paper Reading Note | HyattDD Blog</title><meta name="author" content="Hyatt.D"><meta name="copyright" content="Hyatt.D"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Some notes and thinking while reading MapReduce paper"><link rel="shortcut icon" href="/img/webpic.png"><link rel="canonical" href="http://example.com/2023/01/18/MapReduce%20-%20Paper%20Reading/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":999,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MapReduce Paper Reading Note',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-02-01 18:27:15'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = url => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      link.onload = () => resolve()
      link.onerror = () => reject()
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/font.css"><meta name="generator" content="Hexo 6.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/touxiang.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">10</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="HyattDD Blog"><span class="site-name">HyattDD Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">MapReduce Paper Reading Note</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-01-18T12:20:00.000Z" title="Created 2023-01-18 20:20:00">2023-01-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-02-01T10:27:15.801Z" title="Updated 2023-02-01 18:27:15">2023-02-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/System/">System</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="MapReduce Paper Reading Note"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h1>Introduction</h1>
<h2 id="What-is-MapReduce">What is MapReduce</h2>
<div class="note info no-icon simple"><p>MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper.</p>
</div>
<p>Mapreduce 是一种用于处理和生成大型数据集的编程模型和相关实现，其计算采用一组输入键/值对，并产生一组输出键/值对。由用户指定一个 map 函数处理键/值对以生成一组中间键/值对，以及一个 reduce 函数合并与同一中间键关联的所有中间值。中间值通过迭代器提供给用户的 reduce 函数。这使我们能够处理太大而无法放入内存的值列表。MapReduce 的结果是生成一个数据集合 set，最简单的例子 WordCount 也是得到了每个词以及其对应的词频这样的 pair set</p>
<h2 id="What-Does-MapReduce-Do">What Does MapReduce Do</h2>
<p>The run-time system 运行时系统负责的内容有：</p>
<p><strong>划分</strong>：takes care of the details of partitioning the input data</p>
<p><strong>调度</strong>：scheduling the program’s execution across a set of machines</p>
<p><strong>处理异常与通信</strong>：handling machine failures, and managing the required inter-machine communication</p>
<p>运行时系统的存在可以简化普通人使用分布式系统的复杂性，这也是成熟框架要为用户提供的内容。对于想要利用 MapReduce 框架进行数据处理的开发者来说，只需要实现一个 Map 函数，一个 Reduce 函数即可</p>
<h2 id="MapReduce-处理什么样的数据">MapReduce 处理什么样的数据</h2>
<p>例如倒排索引、Web 文档图形结构的各种表示、每个主机抓取的页面数量的摘要、最频繁查询的集合等</p>
<h2 id="MapReduce-解决什么样的痛点">MapReduce 解决什么样的痛点</h2>
<p>如何并行计算、分发数据和处理故障等问题很复杂，让原本简单的计算也必须要用大量复杂的代码来处理，MapReduce 解决了上述痛点，其抽象灵感来自于 Lisp 和许多其他函数式语言中存在的 map 和 reduce 原语。</p>
<h2 id="MapReduce-具体逻辑">MapReduce 具体逻辑</h2>
<p>大部分计算都涉及对输入中的每个逻辑“记录”应用 map 操作，以计算一组中间键/值对，然后对共享相同键的所有值使用 reduce 操作</p>
<p>在运行 application 过程中，使用重新执行作为容错的主要机制</p>
<h1>Model and Examples</h1>
<h3 id="Model">Model</h3>
<p>Map 函数，顾名思义就是一个映射函数，它会接受一个 key-value 对，然后把这个 key-value 对转换成 0 到多个新的 key-value 对并输出出去。</p>
<p>Reduce 函数，则是一个化简函数，它接受一个 Key，以及这个 Key 下的一组 Value，然后化简成一组新的值 Value 输出出去</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">map</span> (k1, v1) -&gt; <span class="built_in">list</span> (k2, v2)</span><br><span class="line">reduce (k2, <span class="built_in">list</span>(v2)) -&gt; <span class="built_in">list</span>(v3)</span><br></pre></td></tr></table></figure>
<p>在 Map 函数和 Reduce 函数之外，开发者还需要指定一下输入输出文件的路径。输入路径上的文件内容，会变成一个个键值对给到 Map 函数。而 Map 函数会运行开发者写好的映射逻辑，把数据作为新的一组键值对输出出去</p>
<h2 id="Word-Counter">Word Counter</h2>
<p>统计一大堆文件里出现的单词词频，结合下面图看就明白了</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230109231313.png" alt="Pasted image 20230109231313"></p>
<h3 id="Map">Map</h3>
<p>在词频统计这个任务中，map 函数将每一个出现的 word 打上标签 1 表示出现过该单词</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">map</span>(String key, String value)</span><br><span class="line">    <span class="comment">// key is fileName, value is fileContents</span></span><br><span class="line">    <span class="keyword">for</span> each word w in value:</span><br><span class="line">        <span class="built_in">EmitIntermediate</span>(w,<span class="string">&quot;1&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="Reduce">Reduce</h3>
<p>reduce 函数将同一种单词的标签 1 都加起来，这一步做的叫做 shuffle，也就是混洗</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">reduce</span>(String key, Iterator values):</span><br><span class="line">    <span class="comment">// key is a word, values are a list of counts</span></span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> each v in values:</span><br><span class="line">        result += <span class="built_in">ParseInt</span>(v)</span><br><span class="line">    <span class="built_in">Emit</span>(<span class="built_in">AsString</span>(result))</span><br></pre></td></tr></table></figure>
<h2 id="Grep">Grep</h2>
<p>在一台主机上获取错误日志可以使用：</p>
<p><code>grep &quot;error&quot; access.log &gt; /tmp/error.log.1</code></p>
<p>在每台服务器上，都执行一遍相同的 grep 命令就好了。这个动作就是所谓的“分布式 grep”，在整个 MapReduce 框架下，它其实就是一个只有 Map，没有 Reduce 环节</p>
<p>真实的应用场景下，“分布式 grep”当然不只是用来检索日志。对于谷歌这个全球最大搜索引擎来说，这是完美地用来做网页预处理的方案。通过网络爬虫抓取到的网页内容，你都可以直接存到 GFS 上，这样你就可以撰写一个 Map 函数，从 HTML 的网页中，提取网页里的标题、正文，以及链接。然后你可以再去撰写一个 Map 函数，对标题和正文进行关键词提取。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230115212258.png" alt="Pasted image 20230115212258"></p>
<h2 id="Url-Frequency">Url Frequency</h2>
<p>使用 map 函数处理网页请求与返回，统计到的中间数据格式为&lt;URL, 1&gt;，然后再试用 reduce 进行 count，得到&lt;URL, total count&gt;</p>
<p>具体统计过程如下：</p>
<p>考虑全网的所有数据网页访问日志，数据库就肯定放不下了。我们可以把这些日志以文件的形式放在 GFS 上，然后通过 MapReduce 来做数据统计</p>
<p>Map 函数很简单，它拿到的输入数据是这样的：Key 就是单条日志记录在文件中的行号；Value 就是对应单条记录的字符串，不同字段之间以 Tab 分割</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230115213814.png" alt="Pasted image 20230115213814"></p>
<p>Map 函数只需要通过一个 split 或者类似的函数，对 Value 进行分割，拿到 URL，然后输出一个 List 的 key-value 对。在当前的场景下，这个 List 只有一个 key-value 对：<u>输出的 Key 就是 URL；输出的 Value 为空字符串</u></p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230115214136.png" alt="Pasted image 20230115214136"></p>
<p>这个 URL 肯定不只被访问了一次，因为 MapReduce 框架会把所有相同 URL 的 Map 的输出记录，都混洗给到同一个 Reduce 函数里。所以在这里，Reduce 函数拿到的输入数据是这样的：<u>Key 就是 URL；一个 List 的 Value，里面的每一项都是空字符串</u></p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230115214146.png" alt="Pasted image 20230115214146"></p>
<p>Reduce 函数的逻辑也非常简单，就是把 list 里面的所有 Value 计个数，然后和前面的 Key 拼装到一起，并输出出去。Reduce 函数输出的 list 里，也只有这一个元素。这里意思是说 reduce 返回的键值对数据实际上是存在一个 list 中输出去的，list 中的每个元素都是一个 pair</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230115214458.png" alt="Pasted image 20230115214458"></p>
<p>整个 MapReduce 的过程，其实用一段 Bash 代码也可以实现：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat $input | </span><br><span class="line">   awk &#x27;&#123;print $1&#125;&#x27; |</span><br><span class="line">   sort |</span><br><span class="line">   uniq -c &gt; $output</span><br></pre></td></tr></table></figure>
<p>cat 相当于我们 MapReduce 框架从 HDFS 读取数据；awk 的脚本，是我们实现的 Map 函数；sort 相当于 MapReduce 的混洗，只是这个混洗是在本机上执行的；而最后的 uniq -c 则是实现了 Reduce 函数，在排好序的数据下，完成了同一 URL 的去重计数的工作</p>
<div class="note info no-icon simple"><p><strong>uniq -c命令</strong></p>
<p>uniq -c命令是Linux系统中一个用于统计文本文件中重复行的命令。它会读取标准输入，然后根据每一行是否重复，将不同的行打印出来。每行输出前都会出现一个数字，代表这一行重复的次数</p>
</div>
<p>如果和 MapReduce 框架对照起来：</p>
<ul>
<li>读写 HDFS 文件的内容，对应着 cat 命令和标准输出；</li>
<li>对于数据进行混洗 shuffle，对应着 sort 命令；</li>
<li>整个框架，不同阶段之间的数据传输，用的就是 <strong>标准的输入输出管道</strong></li>
</ul>
<h2 id="Reverse-Web-link-Graph">Reverse Web-link Graph</h2>
<div class="note info no-icon simple"><p><strong>反转web-link图</strong></p>
<p>反转web-link图的实现需要遍历整个web-link图，对每一个节点都进行一次检查，如果发现当前节点有入度，即有多个链接到该节点的其他节点的情况，则将这些链接反向重新连接到当前节点的出度，即当前节点链接到的其他节点。重复以上步骤直到整个web-link图完成反转。</p>
<p>反转web-link图是一种可视化方法，它将用户之间的联系以圆形图表和连接线的形式呈现出来，使人们可以清楚地看到网站中各用户之间的关系。</p>
</div>
<p>一个包含链接的页面叫做一个 source，页面中每个链接指向的 URL 是一个 target，此时实际上是一个 source 对应多条链接，相当于一个 source page 节点有多个出度，而使用 map 函数后得到的是 <code>&lt;target, source&gt;</code> 这样的输出，这个 pair 可以认为表示的是一个 target 链接从某个 source 出来，然后 reduce 得到的是 <code>&lt;target, list(source)&gt;</code>，可以理解为一个 target 可以从一系列的 source 中得到，所以这里实现了中心节点与边缘节点的 &quot; 有向边的方向 &quot; 的反转。示意图如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230115231347.png" alt="Pasted image 20230115231347"></p>
<h2 id="Term-Vector-per-Host">Term-Vector per Host</h2>
<p>术语向量 term vector 是出现在一篇文章中最重要的术语集合列表，一个 term vector 表示一系列 <code>&lt;word, frequency&gt;</code> 的键值对，map 函数给每个输入文件输出一个 <code>&lt;hostname, term vector&gt;</code> pairs，reduce 函数获取给定 host 的 term vectors，将这些 term vectors 累加起来，然后去掉不常出现的术语向量，最后提交一个 <code>&lt;hostname, term vector&gt;</code> pair</p>
<h2 id="Inverted-Index">Inverted Index</h2>
<p>Map 函数对每篇文章进行处理，并输出一系列的&lt;word, document ID&gt;对。Reduce 函数接收给定 word 的所有键值对，对相应的 document ID 进行排序并且输出 <code>&lt;word, list&lt;document ID&gt;&gt;</code> 对。所有输出对的集合构成了一个简单的倒排索引，用了 MapReduce 模型，对单词位置的追踪就变得非常简单了。其实这就有点像 Obsidian 中的双链模型的反向链接，也能起到倒排索引的效果。</p>
<div class="note info no-icon simple"><p><strong>倒排索引</strong></p>
<p>倒排索引是一种技术，它将文本中的词语映射到包含它们的文档的列表。 它使搜索引擎可以快速地找到包含特定词语的文档。 每个字典项都是一个单独的单词，而其对应的值是包含此单词的文档列表。</p>
</div>
<h2 id="Distributed-Sort">Distributed Sort</h2>
<p>Map 函数从每个 record 中抽取出 key，产生&lt;key, record&gt;键值对。Reduce 函数只是简单地将所有对输出。这个计算模型依赖于 Section 4.1 中描述的划分技巧以及 Section 4.2 中描述的排序特性。</p>
<h1>Implementation</h1>
<p>MapReduce 接口有多种不同的实现方式，这些实现都要根据应用场景选择，Google 使用的计算集群是一个有成千上万台 PC 机的集群，他们使用双核 X86 处理器，Linux 操作系统，2-4G 内存，以及 100Mbit/s 或者 1Gbit/s 的商业网络和便宜的 IDE 存储。调度系统会将 job(由一系列 task 组成) 分配到集群中的机器上。因此在设计一个分布式的框架时，需要考虑计算机以及其相关的硬件。</p>
<h2 id="Execution-Overview">Execution Overview</h2>
<p>通过将输入数据自动分割成 M 份，Map 函数得以在多台机器上分布式执行。每一个输入块都能并行地在不同的机器上执行。通过划分函数 (例如，hash(key) mod R) 将中间键划分为 R 份，Reduce 函数也能被分布式地调用。其中划分的数目 R 和划分函数都是由用户指定的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230109231343.png" alt="Pasted image 20230109231343"></p>
<h3 id="Fork">Fork</h3>
<p>用户程序中的 MapReduce 库首先将输入文件划分为 M 片，每片大小一般在 16M 到 64M 之间（由用户通过一个可选的参数指定）。之后，它在集群的很多台机器上都启动了相同的程序拷贝，得到的是一堆 worker 进程（master 是其中一个）。</p>
<p>这里需要注意一点，并不是每一个 map 和 reduce 任务，都会单独建立一个新的 worker 进程来执行。而是 master 进程会把 map 和 reduce 任务分配给有限的 worker，因为<u>一个 worker 通常可以顺序地执行多个 map 和 reduce 的任务</u>。</p>
<h3 id="Assign-Map">Assign Map</h3>
<p>fork 出的程序中有一个程序是特别的，叫 master。剩下的都是 worker，它们接收 master 分配的任务。<u>其中有 M 个 Map 任务和 R 个 Reduce 任务要分配</u>。master 挑选一个空闲的机器 (idle worker) 并且给它分配一个 map 任务或者 reduce 任务</p>
<h3 id="Read">Read</h3>
<p>被分配到 Map 任务的 worker 会去读取相应的输入块的内容。它从输入文件中解析出键值对 (key-value pairs) 并且将每个键值对传送给用户定义的 Map 函数。而由 Map 函数产生的中间键值对缓存在内存中</p>
<h3 id="Local-Write">Local Write</h3>
<p>被缓存的键值对会阶段性地写回本地磁盘，并且被划分函数分割成 R 份。这些缓存对在磁盘上的位置会被回传给 master，master 再负责将这些位置转发给 Reduce worker</p>
<h3 id="Remote-Read">Remote Read</h3>
<p>当 Reduce worker 从 master 那里接收到 local write 环节中的那些位置信息时，它会使用 <strong>远程过程调用 (RPC)</strong> 从 Map worker 的本地磁盘中获取缓存的数据。</p>
<p>当 Reduce worker 读入全部的中间数据之后，它会根据中间键对它们进行排序，这样所有具有相同 key 的键值对就都聚集在一起了。于是可以求得每种 key 对应的 count 了</p>
<p>排序是必须的，因为会有许多不同的 key 被映射到同一个 reduce task 中。如果中间数据的数量太大，以至于不能够装入内存的话，还需要另外的排序，一般是外部排序手段。</p>
<h3 id="Write">Write</h3>
<p>Reduce worker 遍历已经排完序的中间数据。每当遇到一个新的中间键，它会将 key 和相应的中间值传递给用户定义的 Reduce 函数。Reduce 函数的输出会被添加到这个 Reduce 部分的输出文件中</p>
<p>完成以上 6 个步骤后，当所有的 Map tasks 和 Reduce tasks 都已经完成的时候，master 将唤醒用户程序。到此为止，用户代码中的 MapReduce 调用返回。</p>
<p>当成功执行完之后，MapReduce 的执行结果被存放在 R 个输出文件中（每个 Reduce task 对应一个，文件名由用户指定）。通常用户并不需要将 R 个输出文件归并成一个。因为它们通常将这些文件作为另一个 MapReduce 调用的输入，或者将它们用于另外一个能够以多个文件作为输入的分布式应用。</p>
<p><strong>思考</strong>：对于词频统计这种任务，应该是要 merge 这些 output files 吧</p>
<h2 id="Master-Data-Structures">Master Data Structures</h2>
<p><strong>3 states and 1 identity</strong></p>
<p>在 master 中保存了许多的数据结构。对于每个 Map task 和 Reduce task，master 都保存了它们的三种状态：<u>idle，in-progress 或 completed</u>，以及 worker 所在机器的标识 identity（对于非 idle 状态的 tasks 而言） ^ae556e</p>
<p>master 相当于是一个管道，通过它 Map task 所产生的中间文件被传递给了 Reduce task。因此，对于每一个已经完成的 Map task，master 会存储由它产生的 R 个中间文件的位置和大小。当 Map task 完成的时候，master 就会收到位置和大小的更新信息。而这些信息接下来就会逐渐被推送到处于 in-progress 状态的 Reduce task 中</p>
<div class="note info no-icon simple"><p><strong>为什么在map task完成时将文件位置和大小信息推送到in-progress Reduce task中而不是idle task中？</strong></p>
<ol>
<li>
<p>这样做是为了减少网络延迟，因为Map任务完成时，它将文件位置和大小信息推送到Reduce任务中，这样之前的Reduce task执行完就可以立即开始执行堆积的任务而不用等待网络传输文件。另外，in-progress的Reduce task在请求文件信息时更有优势，因为它有更多的时间来处理数据，而idle的task则需要先初始化一些数据。</p>
</li>
<li>
<p>Idle Task是MapReduce框架中的一种特殊任务，主要用于快速响应在空闲时间处理一些轻量级的任务。当MapReduce框架中发现有节点处于空闲状态时，就会启动Idle Task来处理一些轻量级的任务，以充分利用资源。Idle Task可以帮助减少作业执行时间，并能够快速响应用户请求。</p>
</li>
</ol>
</div>
<p><strong>注意</strong>：这几个state 描述的是 task 的状态，不是 worker 和 machine 的状态。不要把 idle task 和 idle worker 搞混，可以理解为 idle task 是让 idle worker/machine 处理的一种特殊 task，最初分配任务时还是会把普通的 map 和 reduce task 分配给 idle worker 的，毕竟最初刚 fork 完时所有的 worker 都是 idle worker。而 in-progress task 是交给 in-progress worker/machine 处理的一般 map 和 reduce 任务，completed task 指的是 MapReduce 程序中完成了的任务，即 Map 或 Reduce 任务都已完成。当一个任务完成时，JobTracker 会将其状态修改为一个 completed task，并将其报告给用户。</p>
<h1>Fault Tolerance</h1>
<h2 id="Worker-Failure">Worker Failure</h2>
<p>MapReduce 库的设计初衷是用成千上万的机器去处理大量的数据，所以它就必须能用优雅的方式对机器故障进行处理</p>
<p>master 会周期性地 ping 每一个 worker。如果经过了一个特定的时间还未从某个 worker 上获得响应，那么 master 会将 worker 标记为 failed。所有由该 worker 完成的 Map task 都被回退为 idle 状态，因此能够被重新调度到其他的 worker 上。同样的，所有 failed worker 正在执行的 Map task 或者 Reduce task 也会被回退为 idle 状态，并被重新调度。</p>
<p>这里就可以看出，对于每个 Map Task 或者 Reduce Task，存储其 state 的重要性</p>
<div class="note info no-icon simple"><p><strong>MapReduce中如何获取在failed worker上处理过的task？</strong></p>
<p>Failed workers上处理过的任务可以通过JobTracker来获取。JobTracker会检查失败的工作者，并将其中的任务重新分配给其他正常的工作者来处理。</p>
</div>
<p><strong>发生故障的机器上已经完成的 Map task 需要重新执行</strong>，其原因是它们的输入是保存在本地磁盘的，因此发生故障之后就不能获取了。而 <strong>已经完成的 Reduce task 并不需要被重新执行</strong>，因为它们的输出是存放在全局的文件系统中的。</p>
<p>当一个 Map task 开始由 worker A 执行，后来又由 worker B 执行（因为 A 故障了）。所有执行 Reduce task 的 worker 都会收到这个重新执行的通知。那些还未从 worker A 中读取数据的 Reduce task 将会从 worker B 中读取数据。</p>
<p>Q: 会存在已经读取完 A 中的数据发现 A 故障，然后重新读取吗？不会的，因为故障了就读不到了，还是等其在 B 上重新执行后再读取。</p>
<p>MapReduce 对于大面积的机器故障是非常具有弹性的。例如，在一次 MapReduce 操作中，网络维护造成了集群中八十台机器在几分钟的时间内处于不可达的状态。MapReduce 的 master 只是简单地将不可达的 worker 机器上的工作重新执行了一遍，接着再继续往下执行，最终完成了 MapReduce 的操作。</p>
<h2 id="Master-Failure">Master Failure</h2>
<p>对于 master，我们可以简单地对上文所述的 master 数据结构做周期性的快照。如果一个 master task 死了，我们可以很快地根据最新的快照来重新启动一个 master task。但是，因为我们只有一个 master，因此故障的概率比较低。所以，在我们的实现中如果 master 出现了故障就只是简单地停止 MapReduce 操作。用户可以检测到这种情况，并且如果他们需要的话可以重新开始一次 MapReduce 操作。</p>
<h2 id="Semantics-in-the-Presence-of-Failures">Semantics in the Presence of Failures</h2>
<div class="note info no-icon simple"><p>主要解决多次 Map 或 Reduce 任务提交的幂等性问题，通过以下方式保证原子性：</p>
<ul>
<li><strong>Map</strong>：如果 master 再次接受到同个 Map 任务的完成消息，则会忽略。</li>
<li><strong>Reduce</strong>：Redcue 任务则通过原子方式将临时文件重命名为最终输出文件。</li>
</ul>
</div>
<p>如果用户提供的 Map 和 Reduce 操作是关于输入值的确定性函数，那么我们分布式的实现在整个程序经过没有出现故障的顺序执行之后，将会产生同样的输出。</p>
<div class="note info no-icon simple"><p><strong>什么是确定性函数？</strong></p>
<p>确定性函数是指在相同的输入参数下，每次都会返回相同的输出值的函数。也就是说，对于给定的输入参数，确定性函数总会有一个特定的输出值。</p>
</div>
<p><u>我们依赖 Map task 和 Reduce task 原子性地提交输出来实现上述特性</u>。每一个正在执行的 task 都会将它的输出写到一个私有的临时文件中。一个 Reduce task 产生一个这样的文件，而一个 Map task 产生 R 个这样的文件（每个 Reduce work 一个）。当一个 Map task 完成的时候，worker 就会给 master 发送一个信息，，其中包含了 R 个临时文件的名字。如果 master 收到了一个来自于已经完成了的 Map task 的完成信息（也就是说如果发送的是 completed task 的相关信息，就会被 master 视而不见），那么它就将它自动忽略。否则，将 R 个文件的名称记录到一个 master 数据结构中。</p>
<p>当一个 Reduce task 完成的时候，Reduce worker 会自动将临时输出文件命名为最终输出文件。如果同一个 Reduce task 在多台机器上运行，那么多个重命名操作产生的最终输出文件名将会产生冲突。<u>对此，我们依赖底层文件系统提供的原子重命名操作来保证最终文件系统中的数据来自一个 Reduce task</u></p>
<p>大多数 Map 和 Reduce 操作是确定性的，即可以以一种确定的顺序执行，使得程序员能够很容易地理解其行为。但当操作是非确定性的时候，我们依然提供了适当的语义。对于特定的一个 Reduce task R1 来说，其输出将会与非确定性程序的 <strong>顺序执行</strong>R1 产生的输出一致；但与之不同的另一个 Reduce task R2 执行结果可能会</p>
<p>和非确定性程序按照 <strong>不同顺序执行</strong>R2 的输出结果一致。</p>
<div class="note info no-icon simple"><p><strong>如何理解程序设计中的semantic</strong></p>
<p>Semantic（语义）是一种描述程序含义的方式。它表示一个程序的功能和意义，让人们可以更好理解代码或者文档中的内容。通常，语义使用抽象的概念来代表代码中的特定行为或意图，从而帮助人们在阅读和理解代码时减少不必要的工作量。</p>
<p>上面说的适当语义就是说一定程度上还是能让人看出程序最后的执行结果，但并不能像确定性函数那样每次都和语义上的预期结果一致</p>
</div>
<p>下面考虑 Map task M 和 Reduce task R1 和 R2。</p>
<p>让 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo stretchy="false">(</mo><msub><mi>R</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e(R_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">R_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的执行结果。更弱的语义意味着，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo stretchy="false">(</mo><msub><mi>R</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e(R_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 可能从 M 的一次执行结果中读取输入，而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo stretchy="false">(</mo><msub><mi>R</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e(R_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 可能从 M 的另一次执行中读取输入。这就扣题了：Semantics in the Presence of Failures，因为这种现象出现的原因就是由于故障导致的。</p>
<h2 id="Locality">Locality</h2>
<p>尽量将输入数据存储在本地磁盘上，避免通过网络传输，且 Map 任务通常在包含了输入数据的机器或就近的机器上执行。这样可以保证大部分的输入数据都能从本地机器读取，节省网络传输消耗。</p>
<h2 id="Task-Granularity">Task Granularity</h2>
<p>我们将 Map 操作分成 M 份，Reduce 操作分成 R 份。在理想的情况下，M 和 R 的值应该要比集群中 worker machine 的数量多得多。让一个 worker 同时进行许多不同的 task 有利于提高动态的负载均衡 (类比：计算机网络中的负载均衡)，同时在一个 worker 故障的时候能尽快恢复。许多已经完成的 Map task 也能尽快地传播到其他所有的 worker machine 上。</p>
<p>在我们的实现中，M 和 R 的大小是有一个实用范围的。因为我们的 master 需要做 O(M+R) 个调度决定，并且还要在内存中保存 O(M*R) 个状态。（但是内存使用的常数还是比较小的，O(M*R) 个 Map task / Reduce task 状态对，每个的大小大概在一个字节）</p>
<p>另外，R 通常受限于用户，因为每个 Reduce task 的输出都分散在不同的输出文件中。事实上，我们会选择 M，因此每个输入文件大概 16MB 到 64MB 的输入文件（因此上文所述的局部性优化会达到最优）。而我们会让 R 成为 worker machine 数量的一个较小的倍数。因此，我们通常在进行 MapReduce 操作时，将 M 设为 200000，R 设为 5000，使用 2000 个 worker machine。</p>
<h2 id="Backup-Tasks">Backup Tasks</h2>
<p>^2cda18</p>
<p>有时候 MapReduce 中会出现这么一种情况：某台机器需要花费很长的时间才能完成最后的几个 Map 和 Reduce 任务，从而拖累了整个 MapReduce 的执行时间，这种机器被称为 straggler 。通常 straggler 的出现原因是由于机器磁盘出现问题，或集群调度系统在这台机器上又分配了其他任务等等。我们最近遇到的一个问题是一台机器的初始化代码有点问题，它会导致处理器的缓存被禁用，在这些受影响的机器上进行的计算速度会下降到原来的百分之一。</p>
<p>我们使用了一个通用机制来解决 straggler 问题，具体实现是通过在 MapReduce 快完成时，master 会把处于 in-progress，即仍在处理中的任务进行备份，通过 backup 进程执行。无论是原始进程还是 backup 进程执行完成，都视做整体的 MapReduce 完成。</p>
<p>这种备份处理机制只会占用比正常情况多几个百分点的计算资源，在处理某些任务，比如后文的排序任务时，关闭了备份处理机制的情况要比正常情况多花费 44% 时间完成。</p>
<h1>Refinements</h1>
<p>对于大多数需求由 Map 和 Reduce 函数提供的功能已经足够了，但是我们还是发现了一些有用的扩展</p>
<h2 id="Partitioning-Function">Partitioning Function</h2>
<p>MapReduce 用户决定他们的 Reduce task 或者输出文件的数目 R。通过一个划分函数，根据中间键值将各个 task 的数据进行划分。默认的划分函数是通过哈希（比如，<code>hash(key) mod R</code>）。这通常会产生非常好的较为均衡的划分。</p>
<p>但是在其他一些情况下，通过键值的其他函数来划分要更好一些。例如，有的时候输出键值是一些 URL，我们希望同一个 host 的内容能放在同一个输出文件中。为了支持这种情况，MapReduce 库的用户可以提供一个特殊的划分函数。例如，使用“<code>hash(Hostname(urlKey)) mod R</code>”作为划分函数，从而让所有来自于同一个 host 的 URL 的内容都输出到同一个输出文件。</p>
<div class="note info no-icon simple"><p><strong>划分函数是如何起作用的</strong></p>
<p><code>hash(HostName(urlKey)) mod R</code>之所以能够实现将所有来自同一个host的URL的内容输出到同一个文件，是因为一个host中的所有url是有相同的Hostname，一个Hostname的hash值当然是相同的</p>
<p>至于mod R就更好理解了，因为要划分为R份，所以mod R避免hash冲突</p>
</div>
<h2 id="Ordering-Guarantees">Ordering Guarantees</h2>
<p>我们确保在一个给定的划分中，中间的键值对都按照键值的升序进行处理。这样的处理顺序确保了每一个划分产生一个排好序的输出文件。这样的话，如果输出文件格式需要支持根据 key 进行有效的随机查找会比较方便。同时，输出的用户也会觉得已经排好序的数据使用起来特别方便。</p>
<p>所以这个排序是为了给后面的 reduce 操作提供方便，不管到底用没用这个有序特性帮助 reduce，至少给人家提供这个特性总是好的</p>
<h2 id="Combiner-Function">Combiner Function</h2>
<p>除了 Map 函数需要读取输入的分片数据之外，Reduce 所在的 worker 去抓取中间数据，一样也需要通过网络。那么要在这里减少网络传输，最简单的办法，就是尽可能让中间数据的数据量小一些。自然，在 MapReduce 的框架里，也不会放过这一点。</p>
<p>MapReduce 允许开发者自己定义一个 Combiner 函数。这个 Combiner 函数，会对在同一个服务器上所有 map 输出的结果运行一次，然后进行数据合并。</p>
<p>如果你想要统计每个域名的访问次数，那么 Map 函数的输出结果，就会是一个域名 + 一次访问计数的 1，既然只是对访问次数计数，我们自然就可以通过一个 Combiner，把 1 万条相同域名的访问记录做个化简。把它们变成 Key 还是域名，Value 就是有多少次访问的数值这样的记录就好了。而这样一化简，reduce 所在的 worker 需要抓取的数据，就从 1 万条变成了 1 条。</p>
<p>实际上，不仅是同一个 Map 函数的输出可以合并，同一台服务器上多个 Map 的输出，我们都可以合并。反正它们都在一台机器上，合并只需要本地的硬盘读写和 CPU，并不需要我们最紧缺的网络资源</p>
<p>以域名的访问次数为例，它的数据分布一定有很强的头部效应，少量 20% 的域名可能占了 80% 的访问记录。这样一合并，我们要传输的数据至少可以减少 60%。如果考虑一台 16 核的服务器，有 16 个 map 的 worker 运行，应该还能再减少 80% 以上。这样，通过一个中间的 Combiner，我们要传输的数据一下子就下降了两个数量级，大大缓解了网络传输的压力。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230117162225.png" alt="Pasted image 20230117162225"></p>
<h2 id="Input-and-Output-Types">Input and Output Types</h2>
<p>MapReduce 库提供了对读入数据文件多种的格式支持。</p>
<p>例如，“text” 格式的输入将每一行作为键值对：key 是文件内的偏移 offset，value 是该行的内容。另外一种比较常用的格式存储一系列按照键进行排序的键值对。每一个输出格式的实现都知道如何将自己进行合理的划分从而能让不同的 Map task 进行处理（例如，text 模式就知道将区域划分到以行为边界）。用户可以通过简单地定义一个 reader 接口来提供一个新的输入类型的实现。事实上，大多数用户只使用了预定义输入类型的很小一部分。</p>
<p>reader 并不一定要从文件中读取数据。例如，我们可以很容易地定义一个从数据库，或者内存中映射的数据结构中读取记录的 reader。</p>
<p>同理，我们也支持产生不同格式的输出数据，用户也能编写新的输出数据格式。</p>
<h2 id="Side-effects">Side-effects</h2>
<p>在有些情况下，MapReduce 的用户会很容易发现 Map 或者 Reduce 操作会产生一些辅助文件作为额外的输出文件。我们依赖应用的编写者去保证这些副作用是原子和幂等的。一般来说，应用会写到一个临时文件中，并且在它完全产生之后，通过一个原子操作将它重命名</p>
<div class="note info no-icon simple"><p><strong>幂等性</strong></p>
<p>幂等性是指一个操作或者事务可以被重复执行多次而不影响结果的属性。一般来说，幂等性是一个重要的安全性特征，因为它可以防止意外的或不正常的多次执行对数据造成的影响。</p>
</div>
<p>对于一个单一的 task 产生的多个输出文件，我们不提供原子性的两阶段提交支持。因此，产生多个输出文件并且有跨文件一致性要求的 task 需要是确定性的。但是这样的限制在实践过程中并不是什么问题。</p>
<h2 id="Skipping-Bad-Records">Skipping Bad Records</h2>
<p>有时候，如果用户的代码中有 bug 的话，会导致 Map 或者 Reduce 操作在某些记录上崩溃。这些 bug 会导致 MapReduce 操作的正常完成。对于这种情况，通常就是去修 bug。不过有时候这是不可行的，也许 bug 是第三方库造成的，而我们并不能得到它的源代码。而且，有时候我们允许忽略掉一些记录，例如在对一个大数据集做分析的时候。因此我们提供了一种可选的执行模式，当 MapReduce 库检测到一些记录会造成崩溃时，就会主动跳过它们，从而保证正常地运行。</p>
<p>每一个 worker 进程都安装了一个 signal handler 用于捕捉段错误和 bug。在调用用户的 Map 和 Reduce 操作之前，MapReduce 库会将参数的序号保存在一个全局变量中。如果用户代码产生了一个信号，signal handler 就会传输一个参数含有序号的 &quot;last gasp&quot;UDP 包给 MapReduce 的 master。当 master 在一个特定的记录中发现了不知一次的错误，这表示在下一次执行相应的 Map 或者 Reduce 操作的时候一个将它跳过。</p>
<h2 id="Local-Execution">Local Execution</h2>
<p>Map 或者 Reduce 函数的调试问题是非常 tricky 的。因为实际的计算发生在分布式的系统中，通常由成百上千台机器组成，并且工作的分配由 master 动态执行。为了帮助调试，分析，以及小规模的测试，我们开发了另外一个 MapReduce 库的实现，它能够在本地机器上顺序执行一个 MapReduce 操作的所有工作。它的控制交给用户，因此计算可以被限定到制定的 Map task 中执行。用户利用指定的 flag（我理解的是）启动程序，然后就能非常简单地使用任何它们觉得有用的调试或者测试工具了</p>
<h2 id="Status-Information">Status Information</h2>
<p>master 运行了一个内置的 HTTP server 并且暴露了一系列供人类使用的状态页。状态页会显示程序的计算过程，例如已经完成了多少个 task，还有多少个 task 正在执行，输入的字节数，中间数据的字节数，输出的字节数，以及处理速度等等。该页还包含了指向各个 task 的标准错误和标准输出链接。用户可以利用这些数据来判断计算会持续多长时间，以及计算是否需要添加更多的资源。这些页面还能用来发现什么时候处理速度比预期地下降好多。</p>
<p>另外，顶层的状态页显示了那些 worker 出错了，以及在它们出错时正在执行哪些 Map 和 Reduce task。这些信息在诊断用户代码出现的 bug 时是非常有用的。</p>
<h2 id="Counter">Counter</h2>
<p>MapReduce Library 提供了一种 Counter Facility 来统计不同事件发生的次数，比如用户可能想统计已经处理了多少个单词、已经索引了多少篇文档等。</p>
<p>为了使用 Counter Facility ，用户需要在程序中创建一个 counter 对象，并在 Map 和 Reduce 函数中进行自增：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Counter* uppercase;</span><br><span class="line">uppercase = GetCounter(<span class="string">&quot;uppercase&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">map</span>(String name, String contents):</span><br><span class="line">    <span class="keyword">for</span> each word w in contents:</span><br><span class="line">        <span class="keyword">if</span> (IsCapitalized(w)):</span><br><span class="line">          uppercase-&gt;Increment();</span><br><span class="line">        EmitIntermediate(w, <span class="string">&quot;1&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>这些 counter 的值会周期性地从各个 worker 中传给 master （在 ping 包中），master 对这些执行成功的 Map 和 Reduce 任务的 counter 值进行累加，当一个 MapReduce 完成后，再返回给用户。</p>
<p>Counter 的当前值也会显示在 master 的状态页上，这样用户就能看到当前的计算进度。当对 counter 值进行累加时，master 需要检查重复执行的 Map 和 Reduce 任务，避免重复累加。</p>
<p>Counter Facility 对于 MapReduce 的完整性检查十分有用，例如有时候用户需要确保 output key/value pairs 的数量精确等于 input key/value pairs。</p>
<h1>Performance</h1>
<p>主要是通过两个计算任务来衡量 MapReduce 的性能，一个是在大约 1TB 的数据中进行特定的模式匹配，另一个是对大约 1TB 的数据进行排序</p>
<p>没有备份处理机制的实验结果要比有备份处理机制的慢得多</p>
<h1>Conclusion</h1>
<p>MapReduce programming model 在 Google 内部得到了广泛的成功应用，作者将这些成功归为以下几个方面：</p>
<ul>
<li>高度封装，没有分布式经验的程序员也能十分容易地使用。</li>
<li>可处理大量不同类型问题，例如可以生成用于 Google web search service 使用的数据、用于排序、用于数据挖掘、用于机器学习的数据等等。</li>
<li>在数千台机器组成的大型集群上部署了 MapReduce 实现，这样能更有效地利用这些计算资源，且能在处理其他需要大量计算的问题上用到。</li>
</ul>
<p>作者在 MapReduce 的开发过程中学到了以下几点：</p>
<ul>
<li>Restricting 编程模型使得并行和分布式计算变得容易，也易于构建具有容错性的计算环境。</li>
<li>网络带宽是稀有资源，MapReduce 中的许多优化都是为了减少网络传输，例如本地化读取策略，中间文件写入本地磁盘、只写入一份中间文件等。</li>
<li>多次执行相同任务可以减少性能缓慢的机器带来的影响，同时还能解决由于机器故障导致的数据丢失问题。</li>
</ul>
<div class="note info no-icon simple"><p><strong>什么是restricting编程模型</strong></p>
<p>Restricting programming model是一种提高应用性能的编程技术，它将开发人员的编程范围限制在一定的范围内，以便使用有限的资源。其主要的目的是增强应用性能，减少代码量和运行时间，以及减少内存占用。这样可以更好地利用有限的系统资源，同时也可以更好地实现复杂功能。</p>
</div>
<h1>Debugger</h1>
<p>map 和 reduce 的任务都是在分布式集群上运行的，这个就给我们对程序 debug 带来了很大的挑战。无论是通过 debugger 做单步调试，还是打印出日志来看程序执行的情况，都不太可行</p>
<p>所以，MapReduce 也为开发者贴心地提供了三个办法来解决这一点。</p>
<p>第一个，是提供一个单机运行的 MapReduce 的库，这个库在接收到 MapReduce 任务之后，会在本地执行完成 map 和 reduce 的任务。这样，你就可以通过拿一点小数据，在本地调试你的 MapReduce 任务了，无论是 debugger 还是打日志，都行得通。</p>
<p>第二个，是在 master 里面内嵌了一个 HTTP 服务器，然后把 master 的各种状态展示出来给开发者看到。这样一来，你就可以看到有多少个任务执行完了，有多少任务还在执行过程中，它处理了多少输入数据，有多少中间数据，有多少输出的结果数据，以及任务完成的百分比等等。同样的，里面还有每一个任务的日志信息。另外通过这个 HTTP 服务器，你还可以看到具体是哪一个 worker 里的任务失败了，对应的错误日志是什么。这样，你就可以快速在线上定位你的程序出了什么错，是在哪台服务器上。</p>
<p>第三个，是 MapReduce 框架里提供了一个计数器（counter）的机制。作为开发者，你可以自己定义几个计数器，然后在 Map 和 Reduce 的函数里去调用这个计数器进行自增。所有 map 和 reduce 的计数器都会汇总到 master 节点上，通过上面的 HTTP 服务器里展现出来。比如，你就可以利用这个计数器，去统计有多少输入日志的格式和预期的不一样。如果比例太高，那么多半你的程序就有 Bug，没有兼容所有合法的日志。比如在 Hadoop 里，通过 JobTracker 就可以查看 Task 的执行情况</p>
<h1>Deficiency</h1>
<p>主要有两个缺陷：</p>
<p>第一点：还没有 100% 做到让用户意识不到“分布式”的存在，无论是 Combiner 还是 Partitioner，都是让开发者意识到，它面对的还是分布式的数据和分布式的程序。这一个问题后来通过 SQL 得到解决，编程界面更友好。</p>
<p>第二点：性能仍然不太理想，这体现在两个方面，一个是每个任务都有比较大的 额外开销（overhead），都需要预先把程序复制到各个 worker 节点，然后启动进程；另一个是所有的中间数据都要读写多次硬盘。map 的输出结果要写到硬盘上，reduce 抓取数据排序合并之后，也要先写到本地硬盘上再进行读取，所以快不起来。这个问题后来通过内存 + 硬盘混合存储得到了解决，内存保存中间数据更快，硬盘保存中间数据更稳定，中间数据丢失可以根据依赖的数据和逻辑重新生成。</p>
<p>关于 overhead 的影响，可以参考一篇有意思的博文 <a target="_blank" rel="noopener" href="http://nathanmarz.com/blog/the-mathematics-behind-hadoop-based-systems.html">The mathematics behind Hadoop-based systems</a></p>
<br></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/MapReduce/">MapReduce</a><a class="post-meta__tags" href="/tags/PaperReading/">PaperReading</a></div><div class="post_share"><div class="social-share" data-image="/./img/touxiang.png" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./img/touxiang.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Hyatt.D</div><div class="author-info__description">Seek truth from the facts.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/HyattDD"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/HyattDD" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:tjudht@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-MapReduce"><span class="toc-number">1.1.</span> <span class="toc-text">What is MapReduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-Does-MapReduce-Do"><span class="toc-number">1.2.</span> <span class="toc-text">What Does MapReduce Do</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce-%E5%A4%84%E7%90%86%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="toc-number">1.3.</span> <span class="toc-text">MapReduce 处理什么样的数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce-%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E7%97%9B%E7%82%B9"><span class="toc-number">1.4.</span> <span class="toc-text">MapReduce 解决什么样的痛点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce-%E5%85%B7%E4%BD%93%E9%80%BB%E8%BE%91"><span class="toc-number">1.5.</span> <span class="toc-text">MapReduce 具体逻辑</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">Model and Examples</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Model"><span class="toc-number">2.0.1.</span> <span class="toc-text">Model</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Word-Counter"><span class="toc-number">2.1.</span> <span class="toc-text">Word Counter</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Map"><span class="toc-number">2.1.1.</span> <span class="toc-text">Map</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce"><span class="toc-number">2.1.2.</span> <span class="toc-text">Reduce</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Grep"><span class="toc-number">2.2.</span> <span class="toc-text">Grep</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Url-Frequency"><span class="toc-number">2.3.</span> <span class="toc-text">Url Frequency</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reverse-Web-link-Graph"><span class="toc-number">2.4.</span> <span class="toc-text">Reverse Web-link Graph</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Term-Vector-per-Host"><span class="toc-number">2.5.</span> <span class="toc-text">Term-Vector per Host</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inverted-Index"><span class="toc-number">2.6.</span> <span class="toc-text">Inverted Index</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Distributed-Sort"><span class="toc-number">2.7.</span> <span class="toc-text">Distributed Sort</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">Implementation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Execution-Overview"><span class="toc-number">3.1.</span> <span class="toc-text">Execution Overview</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Fork"><span class="toc-number">3.1.1.</span> <span class="toc-text">Fork</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Assign-Map"><span class="toc-number">3.1.2.</span> <span class="toc-text">Assign Map</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Read"><span class="toc-number">3.1.3.</span> <span class="toc-text">Read</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Local-Write"><span class="toc-number">3.1.4.</span> <span class="toc-text">Local Write</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Remote-Read"><span class="toc-number">3.1.5.</span> <span class="toc-text">Remote Read</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Write"><span class="toc-number">3.1.6.</span> <span class="toc-text">Write</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Master-Data-Structures"><span class="toc-number">3.2.</span> <span class="toc-text">Master Data Structures</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">Fault Tolerance</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Worker-Failure"><span class="toc-number">4.1.</span> <span class="toc-text">Worker Failure</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Master-Failure"><span class="toc-number">4.2.</span> <span class="toc-text">Master Failure</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Semantics-in-the-Presence-of-Failures"><span class="toc-number">4.3.</span> <span class="toc-text">Semantics in the Presence of Failures</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Locality"><span class="toc-number">4.4.</span> <span class="toc-text">Locality</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Task-Granularity"><span class="toc-number">4.5.</span> <span class="toc-text">Task Granularity</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Backup-Tasks"><span class="toc-number">4.6.</span> <span class="toc-text">Backup Tasks</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">Refinements</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Partitioning-Function"><span class="toc-number">5.1.</span> <span class="toc-text">Partitioning Function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ordering-Guarantees"><span class="toc-number">5.2.</span> <span class="toc-text">Ordering Guarantees</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Combiner-Function"><span class="toc-number">5.3.</span> <span class="toc-text">Combiner Function</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Input-and-Output-Types"><span class="toc-number">5.4.</span> <span class="toc-text">Input and Output Types</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Side-effects"><span class="toc-number">5.5.</span> <span class="toc-text">Side-effects</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Skipping-Bad-Records"><span class="toc-number">5.6.</span> <span class="toc-text">Skipping Bad Records</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Local-Execution"><span class="toc-number">5.7.</span> <span class="toc-text">Local Execution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Status-Information"><span class="toc-number">5.8.</span> <span class="toc-text">Status Information</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Counter"><span class="toc-number">5.9.</span> <span class="toc-text">Counter</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">Performance</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">7.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">8.</span> <span class="toc-text">Debugger</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">9.</span> <span class="toc-text">Deficiency</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/02/03/Distributed%20Machine%20Learning%2002/" title="Distributed Machine Learning 02">Distributed Machine Learning 02</a><time datetime="2023-02-03T15:14:59.000Z" title="Created 2023-02-03 23:14:59">2023-02-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/28/Deep%20Neural%20Network%20Foundation/" title="Deep Neural Network Foundation">Deep Neural Network Foundation</a><time datetime="2023-01-28T12:20:00.000Z" title="Created 2023-01-28 20:20:00">2023-01-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/18/MapReduce%20-%20Paper%20Reading/" title="MapReduce Paper Reading Note">MapReduce Paper Reading Note</a><time datetime="2023-01-18T12:20:00.000Z" title="Created 2023-01-18 20:20:00">2023-01-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/10/Distributed%20Machine%20Learning%2001/" title="Distributed Machine Learning 01">Distributed Machine Learning 01</a><time datetime="2023-01-10T15:14:59.000Z" title="Created 2023-01-10 23:14:59">2023-01-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/01/01/C%20on%20Linux/" title="C on Linux">C on Linux</a><time datetime="2023-01-01T14:14:59.000Z" title="Created 2023-01-01 22:14:59">2023-01-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Hyatt.D</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>