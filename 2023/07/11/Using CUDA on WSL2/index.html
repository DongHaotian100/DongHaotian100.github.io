<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>GPU Programming Basic Knowledge | HyattDD Blog</title><meta name="author" content="Hyatt.D"><meta name="copyright" content="Hyatt.D"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Introducing the basics of GPU programming and preparation for programming with CUDA on WSL2"><link rel="shortcut icon" href="/img/webpic.png"><link rel="canonical" href="http://example.com/2023/07/11/Using%20CUDA%20on%20WSL2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":999,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'GPU Programming Basic Knowledge',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-11 14:14:24'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = url => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      link.onload = () => resolve()
      link.onerror = () => reject()
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/font.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/touxiang.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">38</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">47</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">11</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="HyattDD Blog"><span class="site-name">HyattDD Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">GPU Programming Basic Knowledge</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-07-11T01:00:00.000Z" title="Created 2023-07-11 09:00:00">2023-07-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-07-11T06:14:24.159Z" title="Updated 2023-07-11 14:14:24">2023-07-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Tools/">Tools</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="GPU Programming Basic Knowledge"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h1>Install</h1>
<p>新版本的 Windows NVIDIA 显卡驱动已经内置了对 WSL 2 的支持，所以我们只需 Windows 中有 NVIDIA 显卡驱动即可，而不需要 WSL 2 中另外再安装。WSL 2 中只需要安装 CUDA Toolkit for WSL 2 即可，下面是安装方法。</p>
<p>参考官方指引 <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=WSL-Ubuntu&amp;target_version=2.0&amp;target_type=deb_local">CUDA Toolkit 12.2 Downloads | NVIDIA Developer</a></p>
<p>安装 GCC 和其他依赖项。NVCC 依赖于 GCC 和一些其他基本的构建工具, 如果已经安装过可以忽略：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install build-essential</span><br></pre></td></tr></table></figure>
<p>下载和安装 NVIDIA CUDA Toolkit:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pinsudo </span><br><span class="line">mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600</span><br><span class="line">wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda-repo-wsl-ubuntu-12-2-local_12.2.0-1_amd64.deb</span><br><span class="line">sudo dpkg -i cuda-repo-wsl-ubuntu-12-2-local_12.2.0-1_amd64.debsudo </span><br><span class="line">cp /var/cuda-repo-wsl-ubuntu-12-2-local/cuda-*-keyring.gpg /usr/share/keyrings/</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get -y install cuda</span><br></pre></td></tr></table></figure>
<p>其中如果有# <a target="_blank" rel="noopener" href="https://askubuntu.com/questions/1096930/sudo-apt-update-error-release-file-is-not-yet-valid">sudo apt update error: “Release file is not yet valid”</a>，可以使用下面的命令解决：<code>sudo hwclock --hctosys</code></p>
<p>然后配置环境变量：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">CUDA</span></span><br><span class="line">export CUDA_HOME=/usr/local/cuda</span><br><span class="line">export PATH=$&#123;PATH&#125;:$&#123;CUDA_HOME&#125;/bin</span><br><span class="line">export LD_LIBRARY_PATH=$&#123;CUDA_HOME&#125;/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>然后执行 <code>nvcc -V</code> 即可成功。</p>
<p>注意，我们平时使用 <code>nvidia-smi</code> 查看的内容是显卡状态，其中注明的 CUDA 版本是我们的可以安装的最高版本</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/202307111405192.png" alt="Pasted image 20230710001342"></p>
<p>我们在安装 toolkit 时只需要小于等于上面显示的版本就行。</p>
<p>一些关于 CUDA 目前状态的信息：</p>
<ul>
<li>Ubuntu 18.04 support has reached EOL.</li>
<li>CUDA Math Libraries toolchain uses C++11 features, and a C++11-compatible standard library (libstdc++ &gt;= 20150422) is required on the host.</li>
</ul>
<h1>Introduction of CUDA</h1>
<h2 id="Heterogeneous-computing">Heterogeneous computing</h2>
<p>异构计算是一种计算模型，它利用多种不同类型的处理器或计算设备来执行任务。这些处理器或设备可以具有不同的架构、操作方式和性能特点，如中央处理器（CPU）、图形处理器（GPU）、数字信号处理器（DSP）等。异构计算的目标是通过充分利用不同设备的优势，提高系统整体的计算性能和能效。在异构计算中，任务可以根据其特点和需求分配到最适合执行该任务的设备上，从而实现更高效、更灵活的计算。</p>
<p><strong>那么可以看到异构计算中显而易见的问题就是异构计算设备之间的交互（比如 CPU 和 GPU 之间通过 PCIe 总线传输），或许会成为计算性能的瓶颈，而且异构设备之间如何协调分配不同类型的数据是否也对提高计算任务的效率有重要意义呢？</strong> 留个思考，以后了解再说。</p>
<p>不同的架构涉及的问题就是代码执行前编译出来的结果是不同的，所以如果想将代码到不同架构的设备上计算，一般需要重新编译。</p>
<p>目前我们主要使用的异构设备就是 CPU+GPU</p>
<h2 id="CPU-and-GPU">CPU and GPU</h2>
<p>可以看到 CPU 架构中 cache 占比较大，缓存大所以单核性能比较强，而且控制模块占比也比较大，用于做分支预测、乱序执行这些操作。GPU 中的每个核是比较简单的，而核也比较多，并且这些核是顺序的不是乱序的，没有分支预测功能，也是所谓流式处理核。</p>
<p>CPU 适合处理复杂逻辑的控制，GPU 适合一些可预测的、针对数组的、重复性的数据处理，GPU 上每个线程都是执行相同的指令，只是作用在不同的数据上。</p>
<p>使用 CPU 和 GPU 处理任务的基本思想就是串行代码在 CPU 上执行，并行代码在 GPU 上。CPU 上的线程是重量级线程，切换线程的开销较大，可能需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">10^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> 数量级的 clock cycle，而 GPU 上的线程是轻量级线程，切换代价低至 1 个 clock cycle。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/202307101606889.png" alt="Pasted image 20230710160303"></p>
<h2 id="GPU-Programming">GPU Programming</h2>
<p>GPU 编程主要有三种手段：</p>
<p>一是使用第三方加速库的 API，好处是这些 API 一般性能都很好，调用起来也方便，不用自己写加速代码，但是缺点是只能针对特定情况加速，不够灵活，比较没那么多 API 供我们调用。</p>
<p>二是使用编译制导指令进行代码优化，编译制导指令是一种特殊的注释，可以在代码中指定一些编译器优化的方向和策略。常见的标准比如 OpenACC，OpenMP，对应指令：</p>
<ul>
<li><code>#pragma omp parallel for</code>: 告诉编译器将循环并行化，以便在 GPU 上同时执行多个迭代</li>
<li><code>#pragma acc parallel loop</code>: 告诉编译器将循环并行化，以便在加速器上同时执行多个迭代</li>
</ul>
<p>事实上，编译制导指令提供的内容很丰富，绝大多数场合下我们都不需要使用 CUDA 就能完成自己想要的 GPU 加速功能。</p>
<p>三是使用 CUDA 编程编写算子，我们自定义加速方式。</p>
<h2 id="CUDA">CUDA</h2>
<h3 id="Why-CUDA？">Why CUDA？</h3>
<p>CUDA 提供了一系列的 API 和工具，方便开发者调用 GPU 的接口和功能。CUDA 的编程模型允许开发者使用 C/C++、Fortran 等编程语言编写并行计算的代码，并通过 CUDA 的 API 来管理 GPU 设备、内存和执行模式。</p>
<p>CUDA 的 API 包括了设备管理、内存管理、并行执行、数据传输等功能。我们可以使用这些 API 来初始化 GPU 设备、分配和释放 GPU 内存、启动并行计算任务、在 CPU 和 GPU 之间进行数据传输等操作。</p>
<p>从层次上来讲，CUDA 的 API 还分为：</p>
<ul>
<li>
<p>驱动程序 API：更底层、更原始的API，提供了对GPU硬件的直接访问和控制</p>
</li>
<li>
<p>运行时程序 API：更高层次、更抽象的 API，提供了一系列的函数和工具，简化了 GPU 编程的复杂性。</p>
</li>
</ul>
<p>一般使用运行时程序 API 多一些，因为它提供了更高级的抽象和更简洁的编程模型，使得开发过程更加方便和高效。当然，底层 API 也有其优势，更底层、抽象层次低就更灵活。</p>
<p>CUDA 还提供了一些工具和库，如 CUDA 编译器（nvcc，并且 nvcc 是从 LLVM 开源编译系统为基础开发的）、CUDA 调试器（cuda-gdb）、CUDA 性能分析器（nvprof）等，用于编译、调试和优化 CUDA 程序，更加丰富的库介绍在官方文档中有：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/">CUDA Toolkit Documentation 12.2</a></p>
<h3 id="CUDA-Kernel">CUDA Kernel</h3>
<p>CUDA 算子（CUDA Kernel）是在 CUDA 编程模型中定义的并行计算函数。它是在 GPU 上执行的并行计算任务的基本单元。</p>
<p>CUDA算子使用特殊的语法和标记来定义，并且在GPU上以并行方式执行。每个CUDA算子都有一个特殊的修饰符<code>__global__</code>，用于告诉编译器这是一个在GPU上执行的函数。CUDA算子还可以接收参数，并且使用特殊的语法来指定并行执行的线程数量和线程块数量。</p>
<p>CUDA 算子通过使用<strong>线程和线程块</strong>的概念来实现并行计算。线程是最小的执行单元，每个线程都会执行相同的算子代码，但<strong>可以通过内建的线程 ID 来区分不同的线程</strong>。线程块是线程的分组，每个线程块可以包含多个线程，并且线程块之间可以进行协作和通信。通常编写 CUDA 算子的目的是用于执行计算密集型任务，如矩阵运算、图像处理、神经网络计算等。</p>
<p>编写CUDA算子需要遵循一些规则，以确保正确性和性能。这包括使用合适的线程和线程块的数量、合理地管理内存访问、避免数据竞争等。</p>
<h3 id="CUDA-Core">CUDA Core</h3>
<p>CUDA 核心（CUDA Core）是 NVIDIA GPU 架构中的一个基本计算单元。每个 CUDA 核心都是一个独立的处理单元，可以执行并行计算指令，而且可以执行多个线程，能够在一个时钟周期内完成多个指令的执行。CUDA 核心通常由一组浮点运算单元（FPU）和一组整数运算单元（INT）组成，可以执行浮点运算和整数运算。</p>
<p>不同的 NVIDIA GPU 架构具有不同数量的 CUDA 核心，一般更多的 CUDA 核心意味着更高的计算性能。关于英伟达显卡的架构可以查看 <a target="_blank" rel="noopener" href="https://www.nvidia.cn/technologies/">NVIDIA 技术和 GPU 架构 |英伟达</a></p>
<p>CUDA 核心通过并行执行多个线程来提高计算性能。每个线程都被分配给一个 CUDA 核心，并且可以独立地执行计算任务。通过合理地组织线程和线程块的数量，可以充分利用 GPU 上的 CUDA 核心，实现高效的并行计算。</p>
<h1>CUDA Programming</h1>
<h2 id="Abstract-Model">Abstract Model</h2>
<p>CUDA 作为一个 GPU 编程平台，它的作用就是将 GPU 硬件抽象成一些编程接口供我们调用、组合，而其抽象内容主要可以划分为：<strong>计算、存储</strong>。</p>
<p>例如，GPU 中的这些流式处理器或者说计算单元被抽象成线程，供我们编程时组合、调用来实现需求，还有 GPU 的内存也抽象出来，我们申请 GPU 的内存后可以用来存储数据。</p>
<p>在 CPU+GPU 的架构下，CPU 的角色是 host，而 GPU 的角色是 device，可以理解为 GPU 是来辅助 CPU 进行工作的，我们对于计算密集部分或者说可以数据并行的工作需要用 CUDA Kernel 来创建大量的轻量级线程来执行任务，也可以说 SIMD 类型的任务更适合 GPU。</p>
<h2 id="Organizational-structure-of-CUDA-threads">Organizational structure of CUDA threads</h2>
<p>CUDA 中线程的组织结构从高到低是 Grid, Block, Thread。</p>
<p>其中 Thread 是 CUDA 中最低层级的并行计算单元，所以一个 Block 中有一组互相合作的 Threads，他们能够互相快速共享内存交换数据，这得益于一个 Block 占用 GPU 中的一个流式处理器，且一个 Block 中最多 512 个 Threads。而一个 Grid 中有多个 Block，且每个 Block 中的 Threads 数量是相同的。</p>
<p>我们写的每个 Kernel 函数就会对应一个 Grid，里面有根据 Grid, Block, Thread 组成的三层架构, 并且 Grid 和 Block 中的索引都支持一、二、三维。</p>
<p>比如我们计算某个 Block 里的 Thread ID：</p>
<ul>
<li>
<p>一维的 Block：<code>threadIdx.x</code></p>
</li>
<li>
<p>二维的 Block：<code>threadIdx.x + threadIdx.y*blockDim.x</code></p>
</li>
<li>
<p>三维的 Block：<code>threadIdx.x + threadIdx.y*blockDim.x + threadIdx.z*blockDim.x*blockDim.y</code></p>
</li>
</ul>
<div class="note info no-icon simple"><p><strong>为什么使用三维坐标来组织Block和Thread呢？</strong></p>
<p>使用三维坐标可以更好地表示问题的结构和数据的布局。例如，对于图像处理问题，可以将Grid的一个维度表示为图像的宽度，另一个维度表示为图像的高度，这样每个Block就可以处理图像中的一个小块。同样，对于三维体积数据，可以使用三维坐标来表示。</p>
<p>这样我们就可以避免写下面这种代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = threadIdx % width;</span><br><span class="line">y = threadIdx / width;</span><br></pre></td></tr></table></figure>
</div>
<h2 id="Qualifier">Qualifier</h2>
<p><strong>函数修饰符</strong></p>
<table>
<thead>
<tr>
<th>function</th>
<th>execute</th>
<th>call</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__global__</code></td>
<td>host</td>
<td>device</td>
</tr>
<tr>
<td><code>__host__</code></td>
<td>host</td>
<td>host</td>
</tr>
<tr>
<td><code>__device__</code></td>
<td>device</td>
<td>device</td>
</tr>
</tbody>
</table>
<p>其中 <code>__host__</code> 和 <code>__device__</code> 是可以同时使用的，不确定在哪执行，然后编译时就会编译产生两个版本</p>
<p><strong>变量修饰符</strong></p>
<table>
<thead>
<tr>
<th>修饰符</th>
<th>用途</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__device__</code></td>
<td>声明全局内存</td>
<td>将变量存储于 Global Memory 中</td>
</tr>
<tr>
<td><code>__constant__</code></td>
<td>声明常量内存</td>
<td>将变量存储在 Constant Memory 中，可以被 Grid 中的所有线程读取<br> CPU 代码则通过 runtime 读取</td>
</tr>
<tr>
<td><code>__shared__</code></td>
<td>声明共享内存</td>
<td>将变量存储在 Shared Memory 中<br>只能被 Block 内线程读取</td>
</tr>
<tr>
<td><code>volatile</code></td>
<td>声明易失变量</td>
<td>表明变量可能会被多个线程同时访问和修改，防止编译器优化对变量的读写操作</td>
</tr>
<tr>
<td><code>__restrict__</code></td>
<td>声明无别名限制</td>
<td>表明指针没有别名限制，可以进行更多的优化</td>
</tr>
<tr>
<td><code>__device__ __managed__</code></td>
<td>声明统一内存</td>
<td>表明变量可以在主机和设备之间自动迁移，实现统一内存的使用</td>
</tr>
<tr>
<td>无修饰符</td>
<td>Local 变量</td>
<td>是 Thread 私有，和 Thread 有相同 life cycle</td>
</tr>
</tbody>
</table>
<h2 id="Memory-architecture">Memory architecture</h2>
<p>GPU 上的存储架构通常包括以下几个层次：</p>
<ol>
<li>
<p>寄存器（Register）：寄存器是 GPU 中最快的存储器，位于每个 Thread 的执行单元内部。每个 Thread 都有自己的一组寄存器，用于存储局部变量和临时计算结果。寄存器的读写延迟非常低，在 1 个 clock cycle 左右，但容量有限。</p>
</li>
<li>
<p>共享内存（Shared Memory）：共享内存是 GPU 上的一种高速本地存储器，用于 Block 内部的线程之间共享数据。共享内存的读写延迟在 1 个 clock cycle 左右，容量相对于寄存器较大，但仍然有限。共享内存通常用于存储 Block 之间需要共享的数据，以便提高访问速度。</p>
</li>
<li>
<p>局部内存（Local Memory）：局部内存是 GPU 上的一种存储器，用于存储 Block 内的局部变量和临时计算结果，其本质是 Global Memory 划分出来的空间。局部内存的读写延迟较高，容量相对于寄存器和共享内存较大，但仍然较有限。局部内存通常用于存储无法放入寄存器或共享内存的数据。</p>
</li>
<li>
<p>全局内存（Global Memory）：全局内存是 GPU 上的主存储器，为 Grid 提供存储，位于 GPU 芯片外部的设备内存中。全局内存的读写延迟较高，容量较大。全局内存通常用于存储大量的数据，例如输入输出数据、中间计算结果等。由于全局内存的读写延迟较高，在 500 个 clock cycle 左右。</p>
</li>
</ol>
<p>除了以上几种存储器，还有常量内存（Constant Memory）、纹理内存（Texture Memory）等特殊的存储器，用于特定的应用场景。比如 Constant Memory 是一种只读的存储器，用于存储在 GPU 内核函数执行期间不会发生改变的常量数据；Texture Memory 也是一种特殊的只读存储器，但用于存储图像和其他二维数据。纹理内存具有许多特性，例如双线性插值、边界处理、纹理缓存等，使其在图像处理和模拟等应用中非常有用。通过利用纹理内存的特性，可以实现高效的图像处理操作，例如纹理采样、颜色插值等。</p>
<h3 id="Isolated-Memory">Isolated Memory</h3>
<p>在 CUDA 6.0之前的版本中，CPU 和 GPU 的内存是分离的，需要通过显式的内存操作函数在主机内存和设备内存之间进行数据传输。</p>
<p>一般情况下，在使用 CUDA 之前，需要在主机端分配设备内存，并在计算完成后将结果从设备内存传输回主机内存。一般的内存操作流程如下：</p>
<ol>
<li>
<p>使用<code>cudaMalloc()</code>函数在设备内存中分配空间，例如：<code>cudaMalloc(&amp;devicePtr, size);</code>，其中<code>devicePtr</code>是指向设备内存的指针，<code>size</code>是需要分配的内存大小。</p>
</li>
<li>
<p>使用<code>cudaMemcpy()</code>函数将数据从主机内存拷贝到设备内存，例如：<code>cudaMemcpy(devicePtr, hostPtr, size, cudaMemcpyHostToDevice);</code>，其中<code>hostPtr</code>是指向主机内存数据的指针，<code>size</code>是要拷贝的数据大小，<code>cudaMemcpyHostToDevice</code>表示从主机内存到设备内存的拷贝方向。</p>
</li>
<li>
<p>调用CUDA核函数，在设备上进行并行计算。核函数将在设备上的多个线程中执行，每个线程负责处理一个数据元素或一个数据块。</p>
</li>
<li>
<p>使用<code>cudaMemcpy()</code>函数将计算结果从设备内存拷贝回主机内存，例如：<code>cudaMemcpy(hostPtr, devicePtr, size, cudaMemcpyDeviceToHost);</code>，其中<code>hostPtr</code>是指向主机内存的指针，<code>size</code>是要拷贝的数据大小，<code>cudaMemcpyDeviceToHost</code>表示从设备内存到主机内存的拷贝方向。</p>
</li>
<li>
<p>使用<code>cudaFree()</code>函数释放设备内存，例如：<code>cudaFree(devicePtr);</code>，其中<code>devicePtr</code>是要释放的设备内存指针。</p>
</li>
</ol>
<p>需要注意的是，显式的内存操作会引入数据传输的开销，因此在设计 CUDA 程序时，应尽量减少数据的拷贝次数。</p>
<p>举个例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA核函数，将数组元素加倍</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">doubleArray</span><span class="params">(<span class="type">int</span>* deviceArray, <span class="type">int</span> size)</span> &#123;</span><br><span class="line">    <span class="type">int</span> tid = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (tid &lt; size) &#123;</span><br><span class="line">        deviceArray[tid] *= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> size = <span class="number">10</span>;</span><br><span class="line">    <span class="type">int</span> hostArray[size] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>&#125;;</span><br><span class="line">    <span class="type">int</span>* deviceArray;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在设备内存中分配空间</span></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;deviceArray, size * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将数据从主机内存拷贝到设备内存</span></span><br><span class="line">    cudaMemcpy(deviceArray, hostArray, size * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在设备上调用CUDA核函数进行并行计算</span></span><br><span class="line">    <span class="type">int</span> blockSize = <span class="number">256</span>;</span><br><span class="line">    <span class="type">int</span> gridSize = (size + blockSize - <span class="number">1</span>) / blockSize;</span><br><span class="line">    doubleArray&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(deviceArray, size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将计算结果从设备内存拷贝回主机内存</span></span><br><span class="line">    cudaMemcpy(hostArray, deviceArray, size * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印计算结果</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Computed array: &quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, hostArray[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放设备内存</span></span><br><span class="line">    cudaFree(deviceArray);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面代码中 <code>cudaMalloc</code> 函数可以在 GPU 的全局内存中分配指定大小的内存块，并返回指向该内存块的指针。使用 <code>cudaMalloc</code> 分配的内存可以在 GPU 上进行计算和访问。<code>gridSize</code> 的值被计算为 <code>(size + blockSize - 1) / blockSize</code>，其中 <code>size</code> 是要处理的数据的大小。这里将 <code>gridSize</code> 设置为能够容纳全部数据的线程网格大小。通过这样的设置，可以确保所有数据都能被并行计算处理，不会有多余的线程被浪费。至于为什么减 1 则是处理当 size 为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>∗</mo><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">n*blocksize</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span></span></span></span> 时的特殊情况。</p>
<h3 id="Unified-Memory">Unified Memory</h3>
<p>从 CUDA 6.0版本开始，NVIDIA 引入了统一内存（Unified Memory）的概念，使得 CPU 和 GPU 可以共享同一块内存空间，简化了数据的传输和管理。</p>
<p>统一内存允许开发者在编程时将数据视为一个统一的内存空间，而无需显式地进行主机内存和设备内存之间的数据传输。CUDA运行时系统会自动地将数据在主机内存和设备内存之间进行迁移，以保证CPU和GPU都能访问到数据。这样，开发者可以更方便地编写CUDA程序，无需手动管理数据的拷贝和迁移。</p>
<p>在使用统一内存时，我们可以使用 <code>cudaMallocManaged()</code> 函数来分配统一内存。分配的内存既可以在 CPU 上访问，也可以在 GPU 上访问。此外，可以使用 <code>__managed__</code> 修饰符来声明统一内存的变量，使其能够在 CPU 和 GPU 之间共享。</p>
<p>需要注意的是，尽管统一内存使得CPU和GPU的内存看起来是统一的，但实际上数据的迁移仍然发生在后台，可能会引入一定的延迟。因此，在使用统一内存时，仍然需要考虑数据访问的优化，以充分发挥GPU的并行计算能力。</p>
<h2 id="Hello-GPU">Hello GPU</h2>
<p>一个简单的 CUDA C编程例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">hello_world</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;GPU: Hello world!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;CPU: Hello world!\n&quot;</span>);</span><br><span class="line">  hello_world&lt;&lt;&lt;<span class="number">1</span>,<span class="number">10</span>&gt;&gt;&gt;();</span><br><span class="line">  cudaDeviceReset();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中 <code>&lt;&lt;&lt;1,10&gt;&gt;&gt;</code> 表示启动一个由1个线程块组成，每个线程块包含10个线程的并行计算。在这个示例中，每个线程都会执行 <code>hello_world</code> 函数，而 <code>cudaDeviceReset()</code> 函数用于重置设备状态，确保在程序结束前，CUDA 的资源得到正确释放。</p>
<h1>Docs</h1>
<p>在 nvcc 编译的时候根据 GPU 架构确定编译指令, 例如：<code>nvcc -arch=sm_60 filename.cu -o1 executableFileName</code></p>
<p>还可以加参数 <code>-g</code>，表示编译成可以 debug 的程序，而 <code>-deviceemu</code> 则表示用 CPU 模拟 GPU</p>
<p>其中 arch 参数可以查询下面的文档：</p>
<ul>
<li>
<p><a target="_blank" rel="noopener" href="https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/">Matching CUDA arch and CUDA gencode for various NVIDIA architectures - Arnon</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#options-for-steering-gpu-code-generation">NVCC</a></p>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/202307111405453.png" alt="Pasted image 20230710214300"></p>
<p>比如 4060 系列显卡支持 NVIDIA Ada Lovelace 架构，那么使用编译时的选项可以为 <code>-arch=sm_89</code>，我们可以在 <code>CMakelists</code> 里面设置 <code>set(CMAKE_CUDA_FLAGS &quot;-arch=sm_89 -g -G -O3&quot;)</code></p>
<div class="note info no-icon simple"><p><strong>命令选项解释</strong></p>
<ul>
<li>
<p><code>-g</code>：这个选项启用了GPU代码的调试信息。通过使用这个选项，我们可以在GPU代码中设置断点、查看变量值等，以便进行GPU代码的调试。</p>
</li>
<li>
<p><code>-G</code>：这个选项允许在GPU代码中进行追踪。通过使用这个选项，我们可以捕获GPU代码的执行轨迹，以便进行性能分析和优化。</p>
</li>
<li>
<p><code>-O3</code>：这个选项启用了最高级别的优化。我们使用这个选项可以让编译器尽可能地对CUDA代码进行优化，以提高执行效率。</p>
</li>
</ul>
</div>
<h1>Reference</h1>
<ol>
<li>
<p><a target="_blank" rel="noopener" href="https://face2ai.com/program-blog/">人工智能编程 | 谭升的博客</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">CUDA C++ Programming Guide</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://www.xuetangx.com/course/bit0809bt0186/16783202?channel=i.area.recent_search">并行编程原理与实践 - 北京理工大学 - 学堂在线</a></p>
</li>
</ol>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CUDA/">CUDA</a><a class="post-meta__tags" href="/tags/GPU/">GPU</a><a class="post-meta__tags" href="/tags/WSL/">WSL</a></div><div class="post_share"><div class="social-share" data-image="/./img/touxiang.png" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./img/touxiang.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Hyatt.D</div><div class="author-info__description">Seek truth from the facts.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">38</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">47</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">11</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/HyattDD"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/HyattDD" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:tjudht@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Install</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">Introduction of CUDA</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Heterogeneous-computing"><span class="toc-number">2.1.</span> <span class="toc-text">Heterogeneous computing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CPU-and-GPU"><span class="toc-number">2.2.</span> <span class="toc-text">CPU and GPU</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU-Programming"><span class="toc-number">2.3.</span> <span class="toc-text">GPU Programming</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA"><span class="toc-number">2.4.</span> <span class="toc-text">CUDA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Why-CUDA%EF%BC%9F"><span class="toc-number">2.4.1.</span> <span class="toc-text">Why CUDA？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CUDA-Kernel"><span class="toc-number">2.4.2.</span> <span class="toc-text">CUDA Kernel</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CUDA-Core"><span class="toc-number">2.4.3.</span> <span class="toc-text">CUDA Core</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">CUDA Programming</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract-Model"><span class="toc-number">3.1.</span> <span class="toc-text">Abstract Model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Organizational-structure-of-CUDA-threads"><span class="toc-number">3.2.</span> <span class="toc-text">Organizational structure of CUDA threads</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Qualifier"><span class="toc-number">3.3.</span> <span class="toc-text">Qualifier</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Memory-architecture"><span class="toc-number">3.4.</span> <span class="toc-text">Memory architecture</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Isolated-Memory"><span class="toc-number">3.4.1.</span> <span class="toc-text">Isolated Memory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Unified-Memory"><span class="toc-number">3.4.2.</span> <span class="toc-text">Unified Memory</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hello-GPU"><span class="toc-number">3.5.</span> <span class="toc-text">Hello GPU</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">Docs</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">Reference</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/11/Using%20CUDA%20on%20WSL2/" title="GPU Programming Basic Knowledge">GPU Programming Basic Knowledge</a><time datetime="2023-07-11T01:00:00.000Z" title="Created 2023-07-11 09:00:00">2023-07-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/06/Paper%20Reading%20Note-Pollux/" title="Paper Reading Note of OSDI2021 Best Paper - Pollux">Paper Reading Note of OSDI2021 Best Paper - Pollux</a><time datetime="2023-07-06T00:00:00.000Z" title="Created 2023-07-06 08:00:00">2023-07-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/06/23/Simple%20Guide%20of%20Bazel/" title="Simple Guide of Bazel">Simple Guide of Bazel</a><time datetime="2023-06-23T11:00:00.000Z" title="Created 2023-06-23 19:00:00">2023-06-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/04/23/Recsys/" title="Recommend System Based on Bipartite Graph">Recommend System Based on Bipartite Graph</a><time datetime="2023-04-23T11:00:00.000Z" title="Created 2023-04-23 19:00:00">2023-04-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/03/27/GNN%20Intro/" title="GNN Background Knowledge">GNN Background Knowledge</a><time datetime="2023-03-27T12:00:00.000Z" title="Created 2023-03-27 20:00:00">2023-03-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Hyatt.D</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>