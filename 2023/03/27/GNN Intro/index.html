<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>GNN Background Knowledge | HyattDD Blog</title><meta name="author" content="Hyatt.D"><meta name="copyright" content="Hyatt.D"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Simple Summary of GNN Background Knowledge of CS244W"><link rel="shortcut icon" href="/img/webpic.png"><link rel="canonical" href="http://example.com/2023/03/27/GNN%20Intro/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":999,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'GNN Background Knowledge',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-29 00:37:53'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = url => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      link.onload = () => resolve()
      link.onerror = () => reject()
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/font.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/touxiang.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">41</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">10</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="HyattDD Blog"><span class="site-name">HyattDD Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">GNN Background Knowledge</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-03-27T12:00:00.000Z" title="Created 2023-03-27 20:00:00">2023-03-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-03-28T16:37:53.914Z" title="Updated 2023-03-29 00:37:53">2023-03-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ML-DL/">ML&amp;DL</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="GNN Background Knowledge"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><h1>Introduction</h1>
<h2 id="Basic-Knowledge-of-Graph">Basic Knowledge of Graph</h2>
<p>基础的知识包括有向图、无向图、图的表示（邻接矩阵、邻接表、二部图）等</p>
<h2 id="Tools-for-Learning-GNN">Tools for Learning GNN</h2>
<p>PyG（PyTorch Geometric）、GraphGym，以及分析工具 SNAP. PY, NetworkX</p>
<p>原因有：图的 size 可能很大，图的拓扑结构可能很复杂，而且不像 image 那样虽然比较复杂但是局部相似性比较好。而且节点并没有一个明确顺序，毕竟一般都是无向图，图还会动态地变化，图的特征也是多模态的。</p>
<h1>Traditional ML for Graph</h1>
<h2 id="ML-with-Graphs">ML with Graphs</h2>
<p>传统机器学习思路处理图结构的数据，基于下面的 baseline，手动确定 feature 的定义，然后将所有的特征输入到神经网络中去</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230328145824.png" alt="Pasted image 20230328145824"></p>
<p>那么确定 feature 就成了重中之重，一般有三个层次的 feature 来刻画一张图，结点层级特征、边层级的特征、图层级的特征</p>
<h4 id="Classic-Graph-ML-Tasks">Classic Graph ML Tasks</h4>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230313182413%201.png" alt="Pasted image 20230313182413 1"></p>
<h2 id="Node-level">Node-level</h2>
<p>为了从结点层次刻画特征，常被考虑的有结点的度（先不考虑有向图），以及结点的中心度 Node centrality（加权考虑结点每个度对应的邻结点），聚类系数和 Graphlet</p>
<h3 id="Node-Centrality">Node Centrality</h3>
<p>结点中心度需要考虑给邻居节点进行加权，那么如何衡量权重，有很多方法，比如特征向量、介数（通过某结点的路径条数）、接近程度（到其他结点的距离）等</p>
<h4 id="Eigenvector-Centrality">Eigenvector Centrality</h4>
<p>节点的特征向量中心度是指一个节点在整个图中与其他节点的联系之间的度。与之相连的节点的中心度越高，则节点的特征向量中心度越高</p>
<p>Node centrality <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">c_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> takes the node importance in a graph into account</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msub><mi>c</mi><mi>v</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><munder><mo>∑</mo><mrow><mi>u</mi><mo>∈</mo><mi>N</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></munder><msub><mi>c</mi><mi>u</mi></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(1)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">c_v = \frac{1}{\lambda} \sum_{u\in N(v)}{c_u} \tag{1}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.8374em;vertical-align:-1.516em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:2.8374em;vertical-align:-1.516em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>但是这个式子是递归的，改写一下：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>c</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>c</mi><mn>2</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi><mi mathvariant="normal">⋮</mi><mpadded height="0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mi></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>c</mi><mi>v</mi></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mfrac><mn>1</mn><mi>λ</mi></mfrac><mo>⋅</mo><msub><mo>∑</mo><mrow><mi>u</mi><mo>∈</mo><msub><mi>N</mi><mn>1</mn></msub></mrow></msub><msub><mi>c</mi><mi>u</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mfrac><mn>1</mn><mi>λ</mi></mfrac><mo>⋅</mo><msub><mo>∑</mo><mrow><mi>u</mi><mo>∈</mo><msub><mi>N</mi><mn>2</mn></msub></mrow></msub><msub><mi>c</mi><mi>u</mi></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi><mi mathvariant="normal">⋮</mi><mpadded height="0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mi></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mfrac><mn>1</mn><mi>λ</mi></mfrac><mo>⋅</mo><msub><mo>∑</mo><mrow><mi>u</mi><mo>∈</mo><msub><mi>N</mi><mi>v</mi></msub></mrow></msub><msub><mi>c</mi><mi>u</mi></msub></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(2)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{bmatrix}
c_1\\
c_2 \\
\vdots \\
c_v 
\end{bmatrix}
= \begin{bmatrix}
\frac{1}{\lambda} \cdot \sum_{u\in{N_1}} c_u\\
\frac{1}{\lambda} \cdot \sum_{u\in{N_2}} c_u\\
\vdots \\
\frac{1}{\lambda} \cdot \sum_{u\in{N_v}} c_u 
\end{bmatrix}
\tag{2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.46em;vertical-align:-2.48em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.95em;"><span style="top:-4.95em;"><span class="pstrut" style="height:7.4em;"></span><span style="width:0.667em;height:5.400em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.667em' height='5.400em' viewBox='0 0 667 5400'><path d='M403 1759 V84 H666 V0 H319 V1759 v1800 v1759 h347 v-84
H403z M403 1759 V0 H319 V1759 v1800 v1759 h84z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.45em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.98em;"><span style="top:-5.8275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.6275em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.7675em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord">⋮</span><span class="mord rule" style="border-right-width:0em;border-top-width:1.5em;bottom:0em;"></span></span></span></span><span style="top:-1.5675em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.48em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.95em;"><span style="top:-4.95em;"><span class="pstrut" style="height:7.4em;"></span><span style="width:0.667em;height:5.400em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.667em' height='5.400em' viewBox='0 0 667 5400'><path d='M347 1759 V0 H0 V84 H263 V1759 v1800 v1759 H0 v84 H347z
M347 1759 V0 H263 V1759 v1800 v1759 h84z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.45em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:5.5948em;vertical-align:-2.5474em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.95em;"><span style="top:-4.95em;"><span class="pstrut" style="height:7.4em;"></span><span style="width:0.667em;height:5.400em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.667em' height='5.400em' viewBox='0 0 667 5400'><path d='M403 1759 V84 H666 V0 H319 V1759 v1800 v1759 h347 v-84
H403z M403 1759 V0 H319 V1759 v1800 v1759 h84z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.45em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0474em;"><span style="top:-5.8898em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">λ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1786em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3998em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.6449em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">λ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1786em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3998em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.745em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mord">⋮</span><span class="mord rule" style="border-right-width:0em;border-top-width:1.5em;bottom:0em;"></span></span></span></span><span style="top:-1.5399em;"><span class="pstrut" style="height:3.6875em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">λ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1786em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3998em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5474em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.95em;"><span style="top:-4.95em;"><span class="pstrut" style="height:7.4em;"></span><span style="width:0.667em;height:5.400em;"><svg xmlns="http://www.w3.org/2000/svg" width='0.667em' height='5.400em' viewBox='0 0 667 5400'><path d='M347 1759 V0 H0 V84 H263 V1759 v1800 v1759 H0 v84 H347z
M347 1759 V0 H263 V1759 v1800 v1759 h84z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.45em;"><span></span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:5.5948em;vertical-align:-2.5474em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>右边的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span> 移到左边，求和部分实际就是邻接矩阵中对应行和集中度向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span> 之积，所以 2 式可以化简成：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>λ</mi><mo>⋅</mo><mi>c</mi><mo>=</mo><mi>A</mi><mo>⋅</mo><mi>c</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(3)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\lambda \cdot c = A \cdot c \tag{3}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">3</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>c</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>c</mi><mn>2</mn></msub><mo>⋯</mo><msub><mi>c</mi><mi>v</mi></msub><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">c=[c_1,c_2\cdots c_v]^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 可以看出集中度向量就是邻接矩阵的特征向量。我们根据 P-F 定理可知最大的特征值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\lambda_{max}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ma</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 总是正数且唯一：</p>
<div class="note info no-icon simple"><p>Perron-Frobenius 定理可以被描述如下：对一个非负矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>，它有一个非负的特征值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">x</mi></mrow></msub><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\lambda_{\rm max}(A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">max</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span>（最大特征值），并且至少有一个非负的特征向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> 与之对应，使得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>v</mi><mo>=</mo><msub><mi>λ</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">x</mi></mrow></msub><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mi>v</mi></mrow><annotation encoding="application/x-tex">Av=\lambda_{\rm max}(A)v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">max</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span>。此外，这个最大特征值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">x</mi></mrow></msub><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\lambda_{\rm max}(A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">max</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span> 具有以下性质：</p>
<ol>
<li>
<p>它是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 的谱半径（矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 的所有特征值的模最大值）。</p>
</li>
<li>
<p>它是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 的谱半径所对应的左特征向量和右特征向量的乘积。</p>
</li>
<li>
<p>如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 的所有元素 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">a_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 都是正数，那么 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">x</mi></mrow></msub><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\lambda_{\rm max}(A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">max</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span> 有唯一的左特征向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span>（所有元素均为正数），除此之外没有其他非负的左特征向量。</p>
</li>
</ol>
</div>
<h4 id="Betweenness-Centrality">Betweenness Centrality</h4>
<p>节点的介数中心度是指该节点在所有最短路径中出现的次数，介数中心度越高，表示该节点在整个图中扮演着重要的桥梁和连接者的角色</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230310215003.png" alt="Pasted image 20230310215003"></p>
<h4 id="Closeness-Centrality">Closeness Centrality</h4>
<p>节点的接近中心度是指该节点到所有其他节点的最短路径之和的倒数。接近中心度越高，表示节点与其他节点之间的关联更紧密，节点的信息传递速度更快</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230310215021.png" alt="Pasted image 20230310215021"></p>
<h3 id="Clustering-Coefficient">Clustering Coefficient</h3>
<p>图神经网络中的聚类系数是用来描述节点在图中的聚集程度的一种指标。它是指一个节点的邻居节点之间形成连接的概率，即这些邻居节点之间形成连接的数量与它们之间可能形成连接的最大数量之比。</p>
<p>在图神经网络中，聚类系数可以用来衡量一个节点与其邻居节点之间是否存在密集的连接。如果一个节点的聚类系数较高，说明它所处的子图中存在许多密集连接，这通常意味着该节点在子图中具有重要性和影响力。</p>
<p>聚类系数可以通过以下公式计算：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>C</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mn>2</mn><msub><mi>E</mi><mi>i</mi></msub></mrow><mrow><msub><mi>k</mi><mi>i</mi></msub><mo stretchy="false">(</mo><msub><mi>k</mi><mi>i</mi></msub><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">C_i = \frac{2E_i}{k_i(k_i-1)} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2963em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">C_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个节点的聚类系数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">E_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个节点邻居节点之间形成连接的数量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">k_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个节点的度数（即与该节点相连的边数）。需要注意的是，在计算聚类系数时，对于度数小于等于 1 的节点，其聚类系数定义为 0。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230310223421.png" alt="Pasted image 20230310223421"></p>
<h3 id="Graphlet">Graphlet</h3>
<p>图神经网络中的 graphlets 是指图中的小子图，它们可以被视为图的基本构建块。这些小子图包含了一些节点和它们之间的边，可以用来描述节点之间的关系和拓扑结构。在图神经网络中，graphlets 可以被用来提取特征，进行节点分类、链接预测等任务。不同类型的 graphlets 可以捕捉不同层次的拓扑结构信息，从而提高模型的性能。</p>
<p>那么图神经网络中的 graphlet 如何确定？</p>
<p>通常通过选择一个节点以及与该节点相邻的 k 个节点和边，形成的一个子图。其中，节点和边的数量是固定的，通常被称为 graphlet 的大小。主要考虑以下几个因素：</p>
<ol>
<li>选择子图的大小：通常，子图的大小取决于任务的需求，例如，如果希望在节点分类或图分类任务中使用 Graphlet，那么子图的大小应该取决于图数据的大小和节点之间的相互关系。在现有的研究中，常用的 graphlet 大小为 3 ~ 5，因为这些 graphlet 可以很好地捕捉节点之间的局部结构信息。实际上，5 个结点大小的 graphlet 就已经有很多种了：</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230328160534.png" alt="Pasted image 20230328160534"></p>
<ol start="2">
<li>
<p>选择需要包含的节点和边的类型：在构建 graphlet 时，需要确定包括哪些节点和边的类型。例如，在社交网络中，可能只需要包含用户之间的关系，而在蛋白质分子中，需要包含原子之间的关系。</p>
</li>
<li>
<p>选择图中的位置和区域：当选择 graphlet 时，需要选择 graphlet 的位置和区域。通常，选择可以是随机的，也可以是基于一些先验知识的。一些研究者通过滑动窗口的方式来选择 graphlet 的位置和区域，可以在整个图上选择多个 graphlet。</p>
</li>
</ol>
<p>也有一些特殊的办法，比如考虑使用节点周围的小三角结构来表示 graphlet。这种方法被称为“motif counting”，在图神经网络中被广泛使用。它的基本思想是从图形中提取一些小图形（例如，三角形或四边形），并计算这些小图形在整个图形中的数量，并将其作为图形的特征向量中的元素。这些特征向量可以用于训练分类或聚类模型，或者用于其他图形分析任务。因此，节点周围的小三角结构是一种常用的图形特征表示方法之一。</p>
<p>再如，也可以看 graphlet 之间是否是同构的：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230328160258_1.png" alt="Pasted image 20230328160258_1"></p>
<h3 id="Summary">Summary</h3>
<p>总的来说，基于结点重要性的特征，获取到结点在图中的重要性后，可以做一些有用的预测，比如预测一个图中的重要结点，在社交网络中这种重要的结点可能就是 KOL 或者名人。基于结构的特征可以预测一个结点在图中的作用，比如预测蛋白质的功能，因为相似结构的蛋白质功能一般可能类似</p>
<h2 id="Link-level-Features">Link-level Features</h2>
<p>边层次的特征主要有三种：基于距离、基于局部的邻居结点重合度、基于全局的邻居结点。下面首先回顾下边层次的预测任务：</p>
<h3 id="Link-level-Prediction-Tasks">Link-level Prediction Tasks</h3>
<h4 id="Recap">Recap</h4>
<p>在图神经网络中，预测任务指的是利用已有的图数据和标签信息，通过训练模型来预测新的节点或边的标签或属性。这种任务通常被用于节点分类、边预测、链接预测等应用场景中。</p>
<p>在边层次的任务上，模型给出结果时会根据预测概率给出 top-k 个结点对</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230311162708.png" alt="Pasted image 20230311162708"></p>
<p>边层次的预测问题通常有两个部分：</p>
<ol>
<li>
<p>Remove a random set of links and then aim to predict them</p>
</li>
<li>
<p>Given <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>𝐺</mi><mrow><mo stretchy="false">[</mo><msub><mi>𝑡</mi><mn>0</mn></msub><mo separator="true">,</mo><msup><mi>𝑡</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">]</mo></mrow></msub></mrow><annotation encoding="application/x-tex">𝐺_{[ 𝑡_0,𝑡&#x27;]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0385em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span> a graph on edges up to time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mn>0</mn><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup></mrow><annotation encoding="application/x-tex">t_{0}^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1906em;vertical-align:-0.2481em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span></span></span></span> ,output a ranked list L of links (not in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>𝐺</mi><mrow><mo stretchy="false">[</mo><msub><mi>𝑡</mi><mn>0</mn></msub><mo separator="true">,</mo><msubsup><mi>t</mi><mn>0</mn><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup><mo stretchy="false">]</mo></mrow></msub></mrow><annotation encoding="application/x-tex">𝐺_{[𝑡_0,t_0^{&#x27;}]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2227em;vertical-align:-0.5394em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3787em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9516em;"><span style="top:-2.2953em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.6068em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span><span style="top:-2.9516em;margin-right:0.0714em;"><span class="pstrut" style="height:2.6068em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8496em;"><span style="top:-2.8496em;margin-right:0.1em;"><span class="pstrut" style="height:2.5556em;"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5394em;"><span></span></span></span></span></span></span></span></span></span>) that are predicted to appear in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>𝐺</mi><mrow><mo stretchy="false">[</mo><msub><mi>𝑡</mi><mn>1</mn></msub><mo separator="true">,</mo><msubsup><mi>𝑡</mi><mn>1</mn><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">]</mo></mrow></msub></mrow><annotation encoding="application/x-tex">𝐺_{[ 𝑡_1,𝑡_1&#x27;]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0816em;vertical-align:-0.3983em;"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7416em;"><span style="top:-2.1885em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3983em;"><span></span></span></span></span></span></span></span></span></span></p>
</li>
</ol>
<p>然后进行评估：将测试时在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>t</mi><mn>1</mn></msub><mo separator="true">,</mo><msubsup><mi>t</mi><mn>1</mn><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[t_1,t_1^{&#x27;}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1925em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span> 时间段中出现的新边记为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mo>∣</mo><msub><mi>E</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>∣</mo></mrow><annotation encoding="application/x-tex">n=\mid{E_{new}}\mid</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span></span></span></span>，将预测的边集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span> 中的 top-n 条边与其比对</p>
<h4 id="Method">Method</h4>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230311164822.png" alt="Pasted image 20230311164822"></p>
<h3 id="Distance-based-Feature">Distance-based Feature</h3>
<p>比如考虑结点之间的最短路径</p>
<p><strong>Shortest-path distance between two nodes</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230311230254.png" alt="Pasted image 20230311230254"></p>
<h3 id="Local-Neighborhood-Overlap">Local Neighborhood Overlap</h3>
<p>局部程度的公有邻结点</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230311231419.png" alt="Pasted image 20230311231419"></p>
<p>但是有局限性，比如只考虑中间的一个结点，那么现在两个结点中如果是通过多个结点进行连接的，以后很有可能会有更近的接触，比如社交关系就是这样的</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230328163532.png" alt="Pasted image 20230328163532"></p>
<p>于是开始考虑全局的邻结点</p>
<h3 id="Global-Neighborhood-Overlap">Global Neighborhood Overlap</h3>
<p>通过考虑整个 graph，解决了局部邻接点重合特征矩阵中，如果很多节点之间没有直接的一个中间节点就会导致大面积的值为 0 的问题</p>
<p>对于全局邻居节点问题，有 Katz index: count the number of paths of all lengths between a given pair of nodes</p>
<p>计算方法可以借助邻接矩阵的乘法</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230311231819.png" alt="Pasted image 20230311231819"></p>
<p>具体计算细节可以用到了再详细回顾</p>
<h2 id="Graph-level-Features">Graph-level Features</h2>
<p>Goal: We want features that characterize the structure of an <strong>entire graph</strong></p>
<p>需要用到核方法的思想</p>
<div class="note info no-icon simple"><p><strong>核方法</strong></p>
<p>核方法是一种基于核函数的机器学习技术，用于将非线性可分问题转化为线性可分问题。它的基本思想是将原始数据映射到高维空间中，使得在该空间中数据变得线性可分。这个映射过程通过核函数来实现，而不需要明确地计算高维空间中的向量。常见的核函数包括线性核、多项式核、高斯径向基函数等。在机器学习领域中，支持向量机（SVM）是最常见的使用核方法解决分类和回归问题的算法之一。</p>
</div>
<p>Idea: Design kernels instead of feature vectors</p>
<p>图神经网络（GNN）中使用 kernel 方法而不是单纯的使用 feature vectors 的主要原因是，在图上进行卷积/滤波操作时，我们需要对每个节点及其邻居之间的结构信息进行建模。如果只使用特征向量，这些信息很难被捕捉到。kernel 方法更能够高效地捕捉节点之间的结构信息，并且可以更好地适应动态图的变化。</p>
<p>相反，kernel 方法可以通过计算节点之间的相似度来捕捉节点之间的结构信息。具体来说，kernel 方法将每个节点表示为一个向量，并将这些向量输入到核函数中，以计算节点之间的相似度。这些相似度在后续的卷积/滤波操作中被用来计算每个节点的新表征。</p>
<p>另外，由于 GNN 中的图是动态的，即节点和边的出现和消失都是随时间变化的，因此使用 kernel 方法可以比特征向量更好地适应动态图的变化。因为 kernel 方法可以通过在运行时计算相似度矩阵来适应动态图的变化。</p>
<h3 id="Graph-Kernel">Graph Kernel</h3>
<p>图神经网络中的 Graph Kernel 是一种用于衡量两个图之间相似度的函数。它可以将两个图映射到一个向量空间中，并计算它们之间的内积。Graph Kernel 可以被用来解决多种图相关的问题，例如分类、聚类和预测等。</p>
<p>Graph Kernel 通常基于两个图之间的共享特征来计算相似度。这些共享特征可以是节点、边或子图等。Graph Kernel 可以通过不同的方式计算这些共享特征，例如基于路径、子结构或谱分析等。在图神经网络中，Graph Kernel 可以被用来衡量不同节点或子图之间的相似度，并将其作为输入传递给神经网络层。这可以帮助神经网络学习更有效地表示和处理图数据，从而提高模型性能。</p>
<div class="note info no-icon simple"><p><strong>谱分析</strong></p>
<p>图神经网络中的谱分析是一种基于图拉普拉斯矩阵的分析方法，它可以将图结构转化为频域表示，从而实现对图结构的理解和分析。谱分析可以帮助我们探索图结构中的特征、模式和规律，从而为图神经网络的设计和应用提供支持。在谱分析中，常用的工具包括傅里叶变换、特征值分解等。</p>
</div>
<p><strong>Goal</strong></p>
<p>构建一个图的特征向量，这个特征向量（Feature Vector）指的是由图的特征属性构成的向量而不是线性代数中的特征向量（eigenvector）</p>
<p><strong>Key Idea</strong></p>
<p>Bag-of-Words (BoW) for a graph 是一种图神经网络模型，它将图中的节点表示为一个固定长度的向量，类似于文本中的词袋模型。在 BoW 中，每个节点被表示为一个多维向量，其中每个维度对应于一个特征或属性。这些特征可以是节点的度、邻居节点的属性等。然后，这些向量被组合成一个“词袋”，即所有节点的向量按照一定顺序排列并组合成一个大向量。这个大向量可以作为整个图的表示，用于下游任务如分类、聚类等。BoW 模型简单易懂，计算效率高，但可能会丢失部分信息。</p>
<p>为什么考虑用 BoW 模型？</p>
<p>如果我们用最简单的特征构建 Feature Vectors，例如指定颜色的节点数量：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230311235458.png" alt="Pasted image 20230311235458"></p>
<p>就会出现上面的尴尬局面，两个边结构不一样的图 Feature Vector 却一样，所以要考虑将其他特征包含到 feature 中去，例如：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312000351.png" alt="Pasted image 20230312000351"></p>
<p>Both Graphlet Kernel and Weisfeiler-Lehman (WL) Kernel use Bag-of-* representation of graph, where * is more sophisticated than node degrees!</p>
<h3 id="Graphlet-Features">Graphlet Features</h3>
<p><strong>Key idea</strong>: Count the number of different graphlets in a graph</p>
<p><strong>But</strong>：Definition of graphlets here is slightly different from node-level features.</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312000702.png" alt="Pasted image 20230312000702"></p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312000741.png" alt="Pasted image 20230312000741"></p>
<p>图神经网络中的 graphlet feature 是通过计算图中的 graphlet 模式来生成的。Graphlet 是一种小型的、密集连接的子图，通常由 2-5 个节点组成。这些 graphlet 模式可以用来描述图中的局部结构，例如三角形、四元环等。</p>
<p><strong>Step</strong></p>
<p>计算 graphlet feature 的过程通常包括以下步骤：</p>
<ol>
<li>
<p>构建邻接矩阵：将图转换为邻接矩阵表示。</p>
</li>
<li>
<p>构建 graphlet 模板：定义不同大小和形状的 graphlet 模板。</p>
</li>
<li>
<p>计算 graphlet 出现次数：对于每个节点，计算它周围出现各种形状和大小的 graphlet 的数量。</p>
</li>
<li>
<p>统计特征向量：将每个节点周围出现各种形状和大小的 graphlet 的数量组合成一个特征向量，作为该节点的 graphlet feature。</p>
</li>
</ol>
<p>这些特征向量可以用作输入神经网络模型进行训练和预测</p>
<p>形式化描述：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312103925.png" alt="Pasted image 20230312103925"></p>
<p>计算举例：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312103941.png" alt="Pasted image 20230312103941"></p>
<h3 id="Graphlet-Kernel">Graphlet Kernel</h3>
<p>计算方法：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312104226.png" alt="Pasted image 20230312104226"></p>
<p>问题：两个图的大小如果差异很大，数量级不同，数量级小的在计算的 graphlet kernel 中作用会被削弱，所以得标准化一下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312104348.png" alt="Pasted image 20230312104348"></p>
<h3 id="Problem">Problem</h3>
<p>计算图核的成本比较高，所以人们设计了许多不同的图核加快计算，比如 WL Kernel。WL kernel 是一种常用的图神经网络计算方法，用于对图数据进行特征提取和分类。其计算过程如下：</p>
<p><strong>初始化</strong>：将每个节点的标签初始化为一个整数。</p>
<p><strong>迭代</strong>：对于每个迭代轮次 t，执行以下操作：</p>
<ol>
<li>
<p>对于每个节点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span>，将其邻居节点的标签按照大小排序，并将其转换为一个字符串 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span>。</p>
</li>
<li>
<p>将字符串 s 与节点 v 的当前标签 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">l (v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span> 拼接成一个新的字符串 s’。</p>
</li>
<li>
<p>将字符串 s’ 哈希为一个新的整数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>l</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">l&#x27; (v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span>。</p>
</li>
<li>
<p>更新节点 v 的标签为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>l</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">l&#x27; (v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span>。</p>
</li>
</ol>
<p><strong>输出</strong>：将所有节点的标签作为特征向量输出。</p>
<p>在迭代过程中，WL kernel 将每个节点周围邻居节点的信息编码成一个字符串，并通过哈希函数将其转换为一个整数。这样，相似的节点将具有相似的标签，从而可以更好地进行分类和聚类。</p>
<div class="note info no-icon simple"><p><strong>迭代次数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 如何确定</strong></p>
<p>WL kernel 迭代的次数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 通常是一个超参数，需要根据具体任务和数据集进行调整。一般情况下，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 的取值范围为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span>，在迭代 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 次之后，节点的特征向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">h_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 就能够很好地表征它的局部信息和结构。一般来说，比较稠密的图需要更少的迭代次数，而比较稀疏的图需要更多的迭代次数。事实上，在计算 WL kernel 过程中，每一个迭代步骤都会将节点的标签信息进行更新和合并，所以迭代次数的选择要根据具体情况灵活调整</p>
</div>
<h1>Graph Representation Learning</h1>
<p>Graph representation learning, a way to learn node and graph embeddings for downstream tasks, <strong>without feature engineering</strong></p>
<h2 id="Represent-Learning">Represent Learning</h2>
<p>图表示学习可以减轻每次进行特征工程的需要。在传统机器学习中，需要手动选择和提取特征来训练模型，这是一个耗时和费力的过程。但是，在图表示学习中，模型可以自动从图结构中学习到有用的特征，而不需要手动进行特征工程。因此，图表示学习可以减轻每次进行特征工程的负担，使得机器学习更加高效和便捷。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312163312.png" alt="Pasted image 20230312163312"></p>
<h2 id="Encoder-and-Decoder-Framework">Encoder and Decoder Framework</h2>
<p>图表示学习中的 Encoder and Decoder Framework，用于学习一种好的 embedding 方式来将图的结构更好地表示出来</p>
<ul>
<li>Encoder：目标是将每个 Node 映射编码成低维的向量表示，或 embedding</li>
<li>Decoder：目标是利用 Encoder 输出的 Embedding 解码关于图的结构信息</li>
</ul>
<p>这一框架的核心思想在于，如果我们能够基于 <strong>编码</strong> 得到的低维 embeddings，来学习高维 Graph 结构信息的 <strong>解码</strong>，这些信息包括节点的全局位置或节点的局部近邻结构等，那么，原则上，这些低维 emebdding 包含了所有下游机器学习任务所需要的全部信息</p>
<p>Decoder 的输入是 Node Pair 的 embeddings，输出是一个实数，衡量了这两个 Node 在 <strong>原始 Graph</strong> 中的相似性，类似于余弦相似性的感觉</p>
<h2 id="Embedding">Embedding</h2>
<p>在图神经网络中，embedding（嵌入）是将节点、边或子图等实体映射到低维向量空间中的过程。这种映射可以捕捉到实体之间的相似性和关系，从而为后续的任务提供更好的特征表示。通过学习嵌入，图神经网络可以更好地处理复杂的图结构数据，并在节点分类、链接预测、社区检测等任务中取得良好的性能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312163541.png" alt="Pasted image 20230312163541"></p>
<p><strong>Example of 2D embedding</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312163717.png" alt="Pasted image 20230312163717"></p>
<h2 id="Node-Embedding">Node Embedding</h2>
<p>关于 node embedding 的理解有两点需要注意：</p>
<ol>
<li>
<p>The goal is to directly estimate a set of coordinates (i.e., the embedding) of a node so that some aspect of the network structure (captured by Decoder) is preserved. This is unsupervised/self-supervised way of learning node embeddings. So we are not utilizing node labels, and we are not utilizing node features.</p>
<p>学习 embedding 的过程通常是自监督的或者无监督的，具体取决于具体任务和使用的算法。自监督学习是指学习过程不需要人工标注数据标签，而是使用数据本身内在的关联性，通过一些任务让模型学习到有意义的表征，这些表征即 embedding。</p>
<p>例如，对于文本数据，可以使用语言模型对数据进行自监督学习，预测给定文本中缺失的部分，其中预测的缺失部分作为训练样本的输入，而缺失部分的真实值则作为标签。而对于图像数据，可以通过自编码器，让模型学习到如何从高维度的图像数据中提取出有意义的低维度表征。这些学习方式都可以产生有价值的 embedding 表征。在衡量优化效果时，可以使用一些指标，例如分类准确率、聚类准确率、最近邻搜索效率等。同时，也可以使用可视化的方法来直观观察 embedding 空间中相似对象的聚集情况，判断学习到的 embedding 是否与真实关系相符合。</p>
<p>也可以使用无监督方式。在无监督的学习中，训练数据不带有任何标签信息，这时需要使用一些特殊的方法来让模型学会从原始数据中进行有意义的表征学习。通常的方法包括自编码器、奇异值分解、主成分分析等。</p>
<p>例如，可以使用自编码器进行无监督的 embedding 学习。自编码器中包含一个编码器和一个解码器，模型的目标是将输入数据压缩为更小的编码，并且尽可能恢复原始输入。在这个过程中，模型会学会从输入数据中提取出对重建输入有帮助的特征。这些特征就可以被视为 embedding 表征。</p>
<p>在衡量无监督学习的优化效果时，与监督学习类似，可以使用聚类准确率、最近邻搜索效率等指标来衡量 embedding 的质量。常用的无监督 embedding 可视化方法包括 t-SNE 算法等，用于直观地展示 embedding 空间中样本点的分布情况和相互关系。</p>
</li>
<li>
<p>整个 embedding 过程是 task independent 的，什么意思呢，embeddings are task independent，指的是在生成低维度向量时，所使用的算法与具体的任务无关。也就是说，无论是节点分类、图分类还是关系预测等任务，生成的向量都是相同的。这是因为在生成 Embeddings 的过程中，主要考虑的是节点的拓扑结构以及节点之间的相似性，而不考虑特定任务的需求。</p>
<p>因此，Embeddings are task independent 这一性质使得它可以被广泛地应用于各种图分析任务中，而不必重新构建和训练模型。同时也降低了模型的复杂度和训练的难度。</p>
</li>
</ol>
<h3 id="Two-Key-Components">Two Key Components</h3>
<p><strong>Encoder</strong>：用于得到 Embedding 后的 Vector</p>
<p><strong>Similarity Function</strong>：用于根据 Embedding 得到的 vector 判断图的相似性，提供优化目标</p>
<p>图表示学习的节点嵌入（Node Embedding）是将图中的节点映射到低维向量空间中的过程，这个过程叫 encoder。在图神经网络中，常用的节点嵌入方法包括：</p>
<ol>
<li>
<p>Graph Convolutional Network (GCN) Encoder：GCN 是一种基于图卷积的 encoder，使用相邻节点的特征信息和边信息，沿着图结构进行卷积操作，将局部信息进行组合和传递，最终生成节点的向量表示。</p>
</li>
<li>
<p>GraphSAGE Encoder：GraphSAGE 是一种基于采样的 encoder，不同于 GCN 将节点向量的生成结果沿着图结构进行卷积操作，GraphSAGE 会将每个节点周围一定范围内的节点进行聚合，最终生成节点的向量表示。</p>
</li>
<li>
<p>GAT Encoder：GAT 是一种基于自注意力机制的 encoder，可以对节点进行加权组合，以使其考虑到邻居节点间的相互作用。</p>
</li>
</ol>
<p><strong>为什么需要优化 encoder</strong></p>
<p>Embedding 过程本身可以看作是一次以相似度为优化目标的自学习程。在生成 Embedding 向量的过程中，我们通常使用的算法是基于节点之间的相似性来构建节点的低维度向量表征，因此可以将这个过程看作是在自学习相似性特征。具体来说，如果两个节点在图中具有相似的拓扑结构和特征信息，那么它们的低维度向量表征也应该具有较高的相似度。常使用的算法包括 DeepWalk、Node2Vec、GraphSAGE 等，其中很多算法都是基于随机游走的思想，通过对随机游走序列进行训练来构建节点的低维度向量表征。在这些算法中，相似性的计算通常是通过余弦相似度、L2 距离等方式来完成的，而这些相似性计算方式都是以相似度为优化目标的。</p>
<p>在某些情况下，由于不同结点之间的差异较大，结点的 embedding 可能无法捕捉到重要的结点特征，从而影响对它们之间的相似性进行推断，并导致模型性能下降。因此，需要优化 encoder 来使原始网络中的结点相似性和 node embedding 中的相似性接近。通过优化 encoder，可以生成更好的 node embedding，以便更准确地捕捉结点之间的相似性</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312170800.png" alt="Pasted image 20230312170800"></p>
<h3 id="Shallow-Embedding">Shallow Embedding</h3>
<p>Simplest encoding approach: Encoder is just an embedding-lookup</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mi>N</mi><mi>C</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>z</mi><mi>v</mi></msub><mo>=</mo><mi>Z</mi><mo>⋅</mo><mi>v</mi></mrow><annotation encoding="application/x-tex">ENC(v)=z_v=Z\cdot{v}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">ENC</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> 是 indicator vector, all zeroes except a one in column indicating node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span>，也就是 one-hot 编码，Encoder 将节点的 one-hot 编码与一个表示节点特征的权重矩阵相乘，得到每个节点的向量表示。这个权重矩阵就是我们所说的“embedding-lookup”。Each node is assigned a unique embedding vector，we directly optimize the embedding of each node</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312212627.png" alt="Pasted image 20230312212627"></p>
<p>常用的浅层嵌入方法包括随机游走法、局部敏感哈希法和基于矩阵分解的方法等。其中，随机游走法是一种基于链接预测的方法，即根据节点与相邻节点之间的连接信息生成节点序列，然后使用这些序列来训练节点嵌入模型。局部敏感哈希法则是一种利用哈希函数快速近似计算节点之间相似度的方法，可以在保留全局信息的同时有效地降低计算成本。基于矩阵分解的方法则是通过分解邻接矩阵来获取节点的低维表示，如主成分分析、奇异值分解等。</p>
<p>尽管浅层嵌入方法在图神经网络领域中取得了很好的结果，但是由于它无法很好地处理图形的局部结构和高层次特征，因此也催生了更加复杂的深度图神经网络模型的发展，所以后面会讲到深度图神经网络。</p>
<h3 id="Node-Similarity">Node Similarity</h3>
<p>结点相似性是我们需要定义的优化目标</p>
<p><strong>How to define node similarity？</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312213650.png" alt="Pasted image 20230312213650"></p>
<p><strong>node embedding 的方法</strong></p>
<p>常见的 node embedding 方法：</p>
<ol>
<li>
<p>DeepWalk：DeepWalk 是一种基于随机游走的无监督 node embedding 方法。它通过在图上进行随机游走，然后使用 Skip-gram 模型来学习节点嵌入向量。</p>
</li>
<li>
<p>Node2Vec：Node2Vec 是一种改进的 DeepWalk 方法，它使用更复杂的随机游走策略来捕获节点之间更丰富的关系。Node2Vec 使用两个参数来控制随机游走策略：p 控制向后跳转的概率，q 控制向前跳转的概率。<br>
Idea: use flexible, biased random walks that can trade off between local and global views of the network. <u>Node2Vec performs better on node classification while alternative methods perform better on link prediction.</u></p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312221929.png" alt="Pasted image 20230312221929"></p>
</li>
<li>
<p>LINE：LINE（Large-scale Information Network Embedding）是一种基于邻居和二阶邻居信息进行节点嵌入学习的方法。它认为两个节点之间的相似度可以通过它们在同一个邻居或二阶邻居中出现的频率来度量。</p>
</li>
<li>
<p>GraphSAGE：GraphSAGE 是一种基于采样和聚合的 node embedding 方法。它通过对每个节点进行采样，并聚合其邻居信息来生成该节点的嵌入向量。</p>
</li>
<li>
<p>GAT：GAT（Graph Attention Network）是一种基于注意力机制进行节点嵌入学习的方法。GAT 通过计算每个节点与其邻居之间的注意力权重来捕获不同节点之间更细粒度的关系。</p>
</li>
</ol>
<p>这些方法都有各自特点和适用场景，选择合适方法需要根据具体问题和数据集特征进行考虑。These embeddings are task independent，they are not trained for a specific task but can be used for any task</p>
<h3 id="Random-Walk">Random Walk</h3>
<p>Random Walk 方法是一种基于随机游走的方法，它可以在图中寻找出现频率较高的模式，具体来说，Random Walk 方法基于一个无向图，在这个图上进行随机游走，即从任意一个节点开始，按照一定概率向其相邻节点移动，并记录下每个节点被访问的次数。最终，通过统计每个节点被访问的次数，并将其作为特征向量输入到神经网络中进行训练和分类。</p>
<p>参数定义：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312214127.png" alt="Pasted image 20230312214127"></p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312214201.png" alt="Pasted image 20230312214201"></p>
<p>两个结点在 random walk 方式下相遇的概率</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312214215.png" alt="Pasted image 20230312214215"></p>
<p>至于 random walk 的方法，是可选择的策略，拿到 embedding 的结果，计算相似度，根据相似度进行优化，优化得方法也可以选择梯度下降之类的</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312215546.png" alt="Pasted image 20230312215546"></p>
<p><strong>Idea</strong>: if random walk starting from node 𝒖 visits 𝒗 with high probability, 𝒖 and 𝒗 are similar (high-order multi-hop information)</p>
<p><strong>Efficiency</strong>: Do not need to consider all node pairs when training; only need to consider pairs that co-occur on random walks</p>
<p>步骤总结：</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312220230.png" alt="Pasted image 20230312220230"></p>
<h3 id="Negative-Sampling">Negative Sampling</h3>
<p>在 GNN 中的 negative sampling 是一种用于训练嵌入模型的技术。它与一般深度学习任务中的 negative sampling 类似，是为了缓解 softmax 计算中的计算量问题和梯度更新的稳定性问题。</p>
<p>具体来讲，对于某个节点的邻居节点，将其视为正样本，从邻居节点的上下文中随机选择一个节点作为负样本。该节点在模型中所对应的嵌入向量被赋予一个与正样本相反的标签，如 -1，以便在训练时与正样本进行区分。</p>
<p>在训练过程中，模型会优化分类器来增加正样本和负样本之间的间隔，使得分类器更容易区分正样本和负样本。通过这种方式，可以缩小 softmax 计算的规模，提高训练效率和速度，并提高模型的泛化能力。</p>
<h3 id="Sample-Anonymous-Walk">Sample Anonymous Walk</h3>
<p>Sampling anonymous walks 是一种在图上进行采样的方法，主要于生成无标签的随机游走序列。无标签的随机游走序列指的是在游走过程中不记录节点的标签信息，只记录节点的顺序信息，因此也被称为匿名游走序列。</p>
<p>这种采样方法是基于随机游走的思想，其中随机游走是指从图中的某个节点开始，以一定的概率规则步进到下一个节点，并在一定步数后终止游走。Sampling anonymous walks 方法将随机游走的过程进行扩展，通过多次独立的随机游走，记录所有的匿名游走序列，以更加全面地刻画图的结构信息。</p>
<p>Sampling anonymity walks 方法可以帮助我们提取节点序列特征，例如在节点嵌入中使用，以便更好地对节点进行聚类、分类、预测等任务。此外，由于不记录节点标签信息，因此该方法可以消除节点标签偏差的影响，降低了节点标签信息的要求。</p>
<h3 id="Node2Vec">Node2Vec</h3>
<p>Node2Vec 是一种图嵌入算法，用于将图中的节点嵌入到低维向量空间中。它是在 DeepWalk 算法的基础上发展而来的。Node2Vec 的思想是，将图中的节点分成不同的类型，每种类型的节点具有不同的语义表示。然后在这种表示下，使用随机游走采样方法，生成节点序列，并在此基础上进行模型训练，得到每个节点的高质量嵌入向量。</p>
<p>Node2Vec 通过调整节点间游走的概率分布，将节点的语义转化为向量表示，从而将图结构转化为向量空间中的几何结构。具体来说，Node2Vec 为每个节点定义了两个参数 p 和 q，用于控制游走的过程。参数 p 控制直接跳转到邻居节点的概率，参数 q 控制向较远节点跳转的概率。通过调整这两个参数，Node2Vec 能够在 &quot; 深入 &quot; 或 &quot; 广度优先 &quot; 之间切换，这使得它能够更好地捕捉节点之间的不同特征。</p>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230328231710.png" alt="Pasted image 20230328231710"></p>
<h3 id="Summary-So-far">Summary So far</h3>
<p><strong>Core idea</strong>: Embed nodes so that distances in embedding space reflect node similarities in the original network.</p>
<p><strong>Different notions of node similarity</strong>:</p>
<ul>
<li>Naive: Similar if two nodes are connected (next)</li>
<li>Neighborhood overlap (covered in Lecture 2)</li>
<li>Random walk approaches (covered today)</li>
</ul>
<p><strong>In general</strong>: Must choose definition of node similarity that matches our application.</p>
<h2 id="Graph-Embedding">Graph Embedding</h2>
<p>Node embedding 的目标是将单个节点嵌入到低维向量空间中。与 Graph embedding 算法不同，Node embedding 算法通常从节点的局部结构和邻居节点信息出发，把节点周围的结构和属性信息考虑在内，对单个节点进行嵌入。常用的 Node embedding 算法包括 DeepWalk、node2vec、LINE、Struc2Vec 等。Node embedding 适用于应对特定节点的属性预测、节点推荐等任务。</p>
<p>相比之下，Graph embedding 的目标是将整个图结构嵌入到低维向量空间中。Graph embedding 算法通常从整个图的全局结构出发，将图中节点和边的关系以及其他图属性考虑在内，对整个图结构进行嵌入。常用的 Graph embedding 算法包括 DeepWalk、node2vec、LINE、SDNE 等。Graph embedding 适用于应对全局统计和结构分析的问题，可以用于图分类、聚类、可视化等任务。</p>
<h2 id="Summary-2">Summary</h2>
<p><img src="https://cdn.jsdelivr.net/gh/hyattdd/cloud_img/blog/Pasted%20image%2020230312232516.png" alt="Pasted image 20230312232516"></p>
<h1>Reading Materials</h1>
<p><a target="_blank" rel="noopener" href="http://snap.stanford.edu/class/cs224w-2019/">CS224W</a></p>
<br>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/GNN/">GNN</a></div><div class="post_share"><div class="social-share" data-image="/./img/touxiang.png" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./img/touxiang.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Hyatt.D</div><div class="author-info__description">Seek truth from the facts.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">41</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/HyattDD"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/HyattDD" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:tjudht@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Basic-Knowledge-of-Graph"><span class="toc-number">1.1.</span> <span class="toc-text">Basic Knowledge of Graph</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tools-for-Learning-GNN"><span class="toc-number">1.2.</span> <span class="toc-text">Tools for Learning GNN</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">Traditional ML for Graph</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ML-with-Graphs"><span class="toc-number">2.1.</span> <span class="toc-text">ML with Graphs</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Classic-Graph-ML-Tasks"><span class="toc-number">2.1.0.1.</span> <span class="toc-text">Classic Graph ML Tasks</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Node-level"><span class="toc-number">2.2.</span> <span class="toc-text">Node-level</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Node-Centrality"><span class="toc-number">2.2.1.</span> <span class="toc-text">Node Centrality</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Eigenvector-Centrality"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">Eigenvector Centrality</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Betweenness-Centrality"><span class="toc-number">2.2.1.2.</span> <span class="toc-text">Betweenness Centrality</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Closeness-Centrality"><span class="toc-number">2.2.1.3.</span> <span class="toc-text">Closeness Centrality</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Clustering-Coefficient"><span class="toc-number">2.2.2.</span> <span class="toc-text">Clustering Coefficient</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Graphlet"><span class="toc-number">2.2.3.</span> <span class="toc-text">Graphlet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Summary"><span class="toc-number">2.2.4.</span> <span class="toc-text">Summary</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Link-level-Features"><span class="toc-number">2.3.</span> <span class="toc-text">Link-level Features</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Link-level-Prediction-Tasks"><span class="toc-number">2.3.1.</span> <span class="toc-text">Link-level Prediction Tasks</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Recap"><span class="toc-number">2.3.1.1.</span> <span class="toc-text">Recap</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Method"><span class="toc-number">2.3.1.2.</span> <span class="toc-text">Method</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Distance-based-Feature"><span class="toc-number">2.3.2.</span> <span class="toc-text">Distance-based Feature</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Local-Neighborhood-Overlap"><span class="toc-number">2.3.3.</span> <span class="toc-text">Local Neighborhood Overlap</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Global-Neighborhood-Overlap"><span class="toc-number">2.3.4.</span> <span class="toc-text">Global Neighborhood Overlap</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Graph-level-Features"><span class="toc-number">2.4.</span> <span class="toc-text">Graph-level Features</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Graph-Kernel"><span class="toc-number">2.4.1.</span> <span class="toc-text">Graph Kernel</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Graphlet-Features"><span class="toc-number">2.4.2.</span> <span class="toc-text">Graphlet Features</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Graphlet-Kernel"><span class="toc-number">2.4.3.</span> <span class="toc-text">Graphlet Kernel</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem"><span class="toc-number">2.4.4.</span> <span class="toc-text">Problem</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">Graph Representation Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Represent-Learning"><span class="toc-number">3.1.</span> <span class="toc-text">Represent Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Encoder-and-Decoder-Framework"><span class="toc-number">3.2.</span> <span class="toc-text">Encoder and Decoder Framework</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Embedding"><span class="toc-number">3.3.</span> <span class="toc-text">Embedding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Node-Embedding"><span class="toc-number">3.4.</span> <span class="toc-text">Node Embedding</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Two-Key-Components"><span class="toc-number">3.4.1.</span> <span class="toc-text">Two Key Components</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Shallow-Embedding"><span class="toc-number">3.4.2.</span> <span class="toc-text">Shallow Embedding</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Node-Similarity"><span class="toc-number">3.4.3.</span> <span class="toc-text">Node Similarity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Random-Walk"><span class="toc-number">3.4.4.</span> <span class="toc-text">Random Walk</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Negative-Sampling"><span class="toc-number">3.4.5.</span> <span class="toc-text">Negative Sampling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sample-Anonymous-Walk"><span class="toc-number">3.4.6.</span> <span class="toc-text">Sample Anonymous Walk</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Node2Vec"><span class="toc-number">3.4.7.</span> <span class="toc-text">Node2Vec</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Summary-So-far"><span class="toc-number">3.4.8.</span> <span class="toc-text">Summary So far</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Graph-Embedding"><span class="toc-number">3.5.</span> <span class="toc-text">Graph Embedding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Summary-2"><span class="toc-number">3.6.</span> <span class="toc-text">Summary</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">Reading Materials</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/04/23/Recsys/" title="Recommend System Based on Bipartite Graph">Recommend System Based on Bipartite Graph</a><time datetime="2023-04-23T11:00:00.000Z" title="Created 2023-04-23 19:00:00">2023-04-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/03/27/GNN%20Intro/" title="GNN Background Knowledge">GNN Background Knowledge</a><time datetime="2023-03-27T12:00:00.000Z" title="Created 2023-03-27 20:00:00">2023-03-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/03/05/Hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/" title="Hadoop cluster configuration">Hadoop cluster configuration</a><time datetime="2023-03-05T12:00:00.000Z" title="Created 2023-03-05 20:00:00">2023-03-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/02/22/Gradle%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" title="Gradle Tutorial by chat-GPT">Gradle Tutorial by chat-GPT</a><time datetime="2023-02-22T12:00:00.000Z" title="Created 2023-02-22 20:00:00">2023-02-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/02/15/Computational%20Graph/" title="Computational Graph - Theory and Implementation">Computational Graph - Theory and Implementation</a><time datetime="2023-02-15T12:20:00.000Z" title="Created 2023-02-15 20:20:00">2023-02-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Hyatt.D</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>